{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:12.163515606Z",
     "start_time": "2026-03-01T22:39:12.137203619Z"
    }
   },
   "source": [
    "from datasets import load_dataset, Dataset, load_from_disk\n",
    "from datasets.formatting.formatting import LazyBatch\n",
    "\n",
    "from assistant_mask import assistant_mask\n",
    "from chat_template import encode_chat\n",
    "from load_pre_trained import model, tokenizer"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:12.184720290Z",
     "start_time": "2026-03-01T22:39:12.167229090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 5_000\n",
    "processes = 8\n",
    "context_length = model.config.n_positions"
   ],
   "id": "c89d606b7deebcb5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:12.203045864Z",
     "start_time": "2026-03-01T22:39:12.193891637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_and_enrich_messages(batch: LazyBatch):\n",
    "    messages = zip(batch[\"input\"], batch[\"output\"], batch[\"instruction\"])\n",
    "    tokenized = [\n",
    "        encode_chat(instruction=instruction, output=output, input=input)\n",
    "        for input, output, instruction in messages\n",
    "    ]\n",
    "    masks = list(map(assistant_mask, tokenized))\n",
    "    return {\"tokens\": tokenized, \"assistant_mask\": masks}\n",
    "\n",
    "\n",
    "def tokenize_and_prepare_dataset(ds: Dataset):\n",
    "    ds = ds.map(\n",
    "        tokenize_and_enrich_messages,\n",
    "        batched=True,\n",
    "        batch_size=batch_size,\n",
    "        num_proc=processes\n",
    "    )\n",
    "    ds = ds.select_columns([\"tokens\", \"assistant_mask\"])\n",
    "    ds = ds.filter(\n",
    "        lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "        num_proc=processes,\n",
    "    )\n",
    "    return ds"
   ],
   "id": "56d5869fcbefcbd",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:13.899964886Z",
     "start_time": "2026-03-01T22:39:12.208861986Z"
    }
   },
   "cell_type": "code",
   "source": "ds = load_dataset(\"tatsu-lab/alpaca\", split=\"train\").select_columns([\"input\", \"output\", \"instruction\"])",
   "id": "c09634424bbdc9de",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:14.330327662Z",
     "start_time": "2026-03-01T22:39:13.935966539Z"
    }
   },
   "cell_type": "code",
   "source": "ds = tokenize_and_prepare_dataset(ds)",
   "id": "52f78e6df1a39092",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:14.614902099Z",
     "start_time": "2026-03-01T22:39:14.332006035Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits = ds.train_test_split(\n",
    "    test_size=0.08,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "ds_test = splits[\"test\"].save_to_disk(\"tokenized_data/test\")\n",
    "ds_train = splits[\"train\"].save_to_disk(\"tokenized_data/train\")"
   ],
   "id": "213ef74aa1232e87",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/4161 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6a284130f8f4c68bbdc202a2ee35bca"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/47840 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bec5d3d8b9e42d9a695eb1abebb855b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:14.628147624Z",
     "start_time": "2026-03-01T22:39:14.616054553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test = load_from_disk(\"tokenized_data/test\")\n",
    "train = load_from_disk(\"tokenized_data/train\")"
   ],
   "id": "b739810d5b43b43",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:14.655872542Z",
     "start_time": "2026-03-01T22:39:14.629542294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(test.num_rows)\n",
    "print(train.num_rows)"
   ],
   "id": "665fd37e0d37a7f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4161\n",
      "47840\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:14.685476135Z",
     "start_time": "2026-03-01T22:39:14.659300270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "row = next(iter(test))\n",
    "token_ids = row[\"tokens\"]\n",
    "mask = row[\"assistant_mask\"]\n",
    "mask_id = tokenizer.convert_tokens_to_ids(\"*\")\n",
    "masked = [token_id if token_mask else mask_id for token_id, token_mask in zip(token_ids, mask)]\n",
    "tokenizer.decode(token_ids)"
   ],
   "id": "bac9201e9e328a15",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Instruction:\\nMerge these two sentences.\\n\\n### Input:\\nThe cat is playing. The dog is sleeping.\\n\\n### Response:\\nThe cat is playing while the dog is sleeping.<|endoftext|>'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-03-01T22:39:14.718666121Z",
     "start_time": "2026-03-01T22:39:14.689717804Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.decode(masked)",
   "id": "122278a76e990d13",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'********************************The cat is playing while the dog is sleeping.<|endoftext|>'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
