{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:37.121567011Z",
     "start_time": "2026-02-10T17:59:37.039740601Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers import Tokenizer, models, trainers, pre_tokenizers\n",
    "\n",
    "tokenizer = Tokenizer(models.BPE(unk_token=\"[UNK]\"))\n"
   ],
   "id": "55e3488fe548a93c",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:37.221653901Z",
     "start_time": "2026-02-10T17:59:37.123584806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "tokenizer.pre_tokenizer.pre_tokenize_str(\"Let's test\\npre-tokenization!\")"
   ],
   "id": "bcfbc5f1f09fdc82",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Let', (0, 3)),\n",
       " (\"'s\", (3, 5)),\n",
       " ('Ġtest', (5, 10)),\n",
       " ('Ċ', (10, 11)),\n",
       " ('pre', (11, 14)),\n",
       " ('-', (14, 15)),\n",
       " ('tokenization', (15, 27)),\n",
       " ('!', (27, 28))]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:37.234228764Z",
     "start_time": "2026-02-10T17:59:37.224775288Z"
    }
   },
   "cell_type": "code",
   "source": [
    "special_tokens=[\"<|endoftext|>\"]\n",
    "trainer = trainers.BpeTrainer(\n",
    "    vocab_size=8000,\n",
    "    special_tokens=special_tokens,\n",
    "    show_progress=False\n",
    ")"
   ],
   "id": "324fe4e2bb855663",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:37.871277832Z",
     "start_time": "2026-02-10T17:59:37.235568752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "files = [\"input.txt\"]\n",
    "tokenizer.train(files, trainer)\n",
    "file_name=\"sw_tokenizer.json\"\n"
   ],
   "id": "3ae5328152083e2a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:38.007042675Z",
     "start_time": "2026-02-10T17:59:37.958758731Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9a85f6c2abbb04ab",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:38.094075295Z",
     "start_time": "2026-02-10T17:59:38.009414130Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers import decoders, processors\n",
    "\n",
    "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "tokenizer.decoder = decoders.ByteLevel()\n",
    "tokenizer.decode(encoding.ids)"
   ],
   "id": "75f2d1c5e7f3c0fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To be, or not to be:\\n\\nThat is \\nthe question.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:38.114352195Z",
     "start_time": "2026-02-10T17:59:38.095239037Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer.save(file_name)",
   "id": "bd39b6da528eb576",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-10T17:59:38.197806853Z",
     "start_time": "2026-02-10T17:59:38.116883355Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load your trained tokenizer\n",
    "tokenizer = Tokenizer.from_file(file_name)\n",
    "\n",
    "text = \"To be, or not to be:\\n\\nThat is \\nthe question.\"\n",
    "\n",
    "# Encode\n",
    "encoding = tokenizer.encode(text)\n",
    "print(encoding.tokens)"
   ],
   "id": "1f9598fc08c814dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['To', 'Ġbe', ',', 'Ġor', 'Ġnot', 'Ġto', 'Ġbe', ':', 'Ċ', 'Ċ', 'That', 'Ġis', 'Ġ', 'Ċ', 'the', 'Ġquestion', '.']\n"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
