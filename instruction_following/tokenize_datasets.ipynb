{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Pre process and tokenize all datasets, save the token ids.",
   "id": "4a59e67f04d60450"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-25T20:49:42.756338875Z",
     "start_time": "2026-02-25T20:49:41.930342071Z"
    }
   },
   "source": [
    "import os\n",
    "\n",
    "from datasets import load_dataset, load_from_disk\n",
    "from datasets.formatting.formatting import LazyBatch\n",
    "from huggingface_hub import login\n",
    "\n",
    "from chat_template import chat_template\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens\n",
    "\n",
    "hf_token = os.getenv(\"HF_TOKEN\")\n",
    "login(hf_token)\n",
    "batch_size = 5_000\n",
    "processes = 8\n",
    "context_length = ModelSettings.max_context_length"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T20:49:43.366536890Z",
     "start_time": "2026-02-25T20:49:43.274113046Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers.tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")"
   ],
   "id": "2d1c914c81b69378",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T20:49:44.212279278Z",
     "start_time": "2026-02-25T20:49:44.203928367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test_tokens(loaded):\n",
    "    token_ids = next(iter(loaded))[\"tokens\"]\n",
    "    text = tokenizer.decode(token_ids)\n",
    "    print(\"token count\", len(token_ids))\n",
    "    print(text)"
   ],
   "id": "bbdc76ace01e6f76",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: no robots",
   "id": "358bd42416aca9b9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:05:32.137223311Z",
     "start_time": "2026-02-15T09:05:23.152452237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_test = load_dataset(\"HuggingFaceH4/no_robots\", split=\"test\").select_columns([\"messages\"])\n",
    "ds_train = load_dataset(\"HuggingFaceH4/no_robots\", split=\"train\").select_columns([\"messages\"])"
   ],
   "id": "486d48ee4cee7365",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:05:34.545570924Z",
     "start_time": "2026-02-15T09:05:32.144488076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_robots(batch: LazyBatch):\n",
    "    results = [\n",
    "        tokenizer.encode(chat_template(row)).ids\n",
    "        for row in batch[\"messages\"]\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test.map(\n",
    "    tokenize_robots,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\")\n",
    "ds_test = ds_test.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_test.save_to_disk(\"tokenized_data/robots_test\")\n",
    "\n",
    "ds_train.map(\n",
    "    tokenize_robots,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes,\n",
    ").select_columns(\"tokens\")\n",
    "ds_train = ds_train.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_train.save_to_disk(\"tokenized_data/robots_train\")"
   ],
   "id": "ff09b2b2d9edd170",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a55b4c956f54b7796bf2542d6aa07a0"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c43330cebc44421e9f577a93c30d3d0f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d788773121c439ca54e2a5646bdbc71"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/9500 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "242466cd58974e3c964d836a2a789cc9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:05:34.586493244Z",
     "start_time": "2026-02-15T09:05:34.547450159Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/robots_test\"))",
   "id": "1ad498e3b3bf1252",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aster is a chatbot who answers questions with rhymes.\n",
      "Where did chocolate originate?\n",
      "Chocolate is 4000 years old/Mexico is where it was first sold\n",
      "Where was milk chocolate invented?\n",
      "Switzerland was the first to add milk/To make their chocolate smooth as silk\n",
      "What are some good desserts that use chocolate?\n",
      "Pie, tart, cookies, and cake/Chocolate is great to bake\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: ultra chat",
   "id": "1bcf00de1d04ed1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T14:46:35.758165665Z",
     "start_time": "2026-02-25T14:46:32.335970855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_train = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"train_sft\")\n",
    "ds_test = load_dataset(\"HuggingFaceH4/ultrachat_200k\", split=\"test_sft\")"
   ],
   "id": "a3c53cd9b7989a8e",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T14:50:28.903247081Z",
     "start_time": "2026-02-25T14:46:36.313649787Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_ultra(batch: LazyBatch):\n",
    "    results = [\n",
    "        tokenizer.encode(chat_template(row)).ids\n",
    "        for row in batch[\"messages\"]\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    tokenize_ultra,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\")\n",
    "ds_test = ds_test.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_test.save_to_disk(\"tokenized_data/ultra_test\")\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    tokenize_ultra,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes,\n",
    ").select_columns(\"tokens\")\n",
    "ds_train = ds_train.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_train.save_to_disk(\"tokenized_data/ultra_train\")"
   ],
   "id": "388a53e5142f0f45",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/23110 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1b96468e5034a07917e4e429efb39c9"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/23110 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "00a598942a7f40449a768448ee4592eb"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/8604 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "de71785dcb46409f9ff84691802e1343"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/207865 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8b880b69bb24293a8d4ed5ac562c17d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/207865 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14013ba95d7041c0b6175382bcbd1005"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/76473 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34e21d88cac349c5b59641b3e81479d7"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T15:07:36.976438716Z",
     "start_time": "2026-02-25T15:07:36.930419617Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/ultra_test\"))",
   "id": "9382775dc43130c6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token count 784\n",
      "Create a t-shirt design that raises awareness for animal rights by including a bold statement or message advocating for animal welfare, using animal prints or illustrations, or portraying animals in a positive way. Incorporate bright and eye-catching colors to make the design stand out and potentially attract more attention to the cause. The design should be visually appealing and memorable, leaving a lasting impression on the viewer.\n",
      "One possible t-shirt design could feature a bold message in white lettering on a black background, reading \"Animals are not ours to exploit.\" Below the text would be an illustration of various animals, such as a tiger, elephant, and gorilla, each depicted in a colorful and stylized manner. The background of the design could incorporate a pattern of animal prints in bright shades of green, blue, and purple, further emphasizing the importance of protecting these creatures and their habitats. The design would be simple but impactful, conveying a strong message in a visually appealing way.\n",
      "I like the design concept, but can we incorporate a quote about animal rights that will resonate with people? Something powerful that will make them stop and think.\n",
      "Absolutely! How about using the quote by Mahatma Gandhi, “The greatness of a nation and its moral progress can be judged by the way its animals are treated”? We can feature the quote in bold white lettering on a multi-colored background composed of various animal prints. Underneath the quote, we can have an illustration of different animals united together, such as a lion, a rhinoceros, an elephant, and a bear, all holding hands or paws. This will help emphasize the idea that all animals should have equal rights and be treated with respect and dignity.\n",
      "I love the multi-colored animal print background! Could we make it a little more dynamic by incorporating some additional imagery, like leaves or trees, to represent animal habitats?\n",
      "Great idea! We can add some leaves or trees to the background of the design to represent different animal habitats. One possibility is to add a tree silhouette in the center of the design, surrounded by a variety of animal prints in vibrant colors. The Mahatma Gandhi quote can be displayed in bold white lettering above the tree, while the animal illustration can be placed below the tree, symbolizing the animals living in a natural environment.\n",
      "\n",
      "The animal illustration could feature different animals such as a tiger, elephant, panda, and turtle, all living in harmony in a verdant forest. The colors of the design can be brighter and more eye-catching, featuring greens, yellows, oranges, and blues in a gradient-like pattern that fades into the animal prints. \n",
      "\n",
      "The final design will be powerful, eye-catching, and memorable, conveying a strong message of respect for animal rights and the importance of protecting their habitats.\n",
      "I think the design looks great so far, but could we include more specific information about what people can do to help protect animal rights and their habitats? Maybe there could be a website URL or social media handle included somewhere on the shirt.\n",
      "Of course! In order to encourage people to take action and learn more about animal rights and their habitats, we could add a website or social media handle to the bottom of the design. Something like \"learnmore.org\" or \"@protectanimals\" could be added in small white lettering, encouraging people to get involved and take the next step. This would make the design not only visually impactful but also practically informative, raising awareness and potentially leading to further action in support of animal rights.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: lmsys",
   "id": "778e0f754c8997e3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T20:51:08.005645749Z",
     "start_time": "2026-02-25T20:49:51.854213033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits = load_dataset(\"lmsys/lmsys-chat-1m\", split=\"train\").take(100_000).train_test_split(\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "ds_test = splits[\"test\"].select_columns([\"conversation\", \"language\"])\n",
    "ds_train = splits[\"train\"].select_columns([\"conversation\", \"language\"])"
   ],
   "id": "508230aebe287f76",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T20:52:08.835960115Z",
     "start_time": "2026-02-25T20:51:22.483288539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_lmsys(batch: LazyBatch):\n",
    "    results = [\n",
    "        tokenizer.encode(chat_template(row)).ids\n",
    "        for row in batch[\"conversation\"]\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    tokenize_lmsys,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns([\"tokens\", \"language\"])\n",
    "ds_test = ds_test.filter(\n",
    "    lambda example: example[\"language\"] == \"English\" and len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_test.save_to_disk(\"tokenized_data/lmsys_test\")\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    tokenize_lmsys,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes,\n",
    ").select_columns([\"tokens\", \"language\"])\n",
    "ds_train = ds_train.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_train.save_to_disk(\"tokenized_data/lmsys_train\")"
   ],
   "id": "da2e6d2e1570ef10",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "69171ab18cd4492d9b2aea393db4f50f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b22ad3063ed04b40b4bcb3996a5dd9bc"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/6816 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e860c946c8ed4799896d370e400a6a2e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec076759732b446d9f2a91e329032ee2"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/90000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "883451875ba546b3bbeddbfad943dbc0"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/76630 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc6623631cff4f75bd1aee5dc6a86722"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T20:52:14.884428426Z",
     "start_time": "2026-02-25T20:52:14.833327624Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/lmsys_test\"))",
   "id": "547331a770942e93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token count 92\n",
      "There is a Corlforl. Now there are two! There are two...\n",
      "It appears that you are describing a situation in which there are now two things or entities that were previously referred to as Corlforl. It is unclear from the information provided what these Corlforls are or what their relationship is to each other. Without more context or information, it is difficult to provide a more detailed response.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: alpaca",
   "id": "16dcdf9b4742c02a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T14:53:02.716740892Z",
     "start_time": "2026-02-25T14:53:00.338038419Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\").train_test_split(\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "ds_test = splits[\"test\"].select_columns([\"input\", \"output\", \"instruction\"])\n",
    "ds_train = splits[\"train\"].select_columns([\"input\", \"output\", \"instruction\"])"
   ],
   "id": "f8251ea7083e6a1d",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T14:53:37.189708175Z",
     "start_time": "2026-02-25T14:53:28.266564628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_alpaca(input, output, instruction):\n",
    "    user_prompt = instruction\n",
    "    if input:\n",
    "        user_prompt += \"\\n\\n\" + input\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "        {\"role\": \"assistant\", \"content\": output},\n",
    "    ]\n",
    "    return chat_template(messages)\n",
    "\n",
    "\n",
    "def tokenize_alpaca(batch: LazyBatch):\n",
    "    rows = zip(\n",
    "        batch[\"input\"],\n",
    "        batch[\"output\"],\n",
    "        batch[\"instruction\"])\n",
    "    results = [\n",
    "        tokenizer.encode(format_alpaca(*row)).ids\n",
    "        for row in rows\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    tokenize_alpaca,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\")\n",
    "ds_test = ds_test.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_test.save_to_disk(\"tokenized_data/alpaca_test\")\n",
    "\n",
    "ds_train = ds_train.map(\n",
    "    tokenize_alpaca,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes,\n",
    ").select_columns(\"tokens\")\n",
    "ds_train = ds_train.filter(\n",
    "    lambda example: len(example[\"tokens\"]) <= context_length,\n",
    "    num_proc=processes,\n",
    ")\n",
    "ds_train.save_to_disk(\"tokenized_data/alpaca_train\")"
   ],
   "id": "719e011996e1d293",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/5176 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67a6b76b2cad441e88fef8db6a841d3c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/5176 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cde0fb7686d74e099205bb9c2dffe7a8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/5176 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2867a8cc277a44ec9477f9fa552e0fee"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/46584 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4fdac5efd2fd44758dde163684243a6d"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Filter (num_proc=8):   0%|          | 0/46584 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f0a1df96a4b43fc8e62860c4565a11f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/46580 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "925547ed88bc48849ff39e451d3d5de4"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T14:53:39.901325360Z",
     "start_time": "2026-02-25T14:53:39.871427749Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/alpaca_test\"))",
   "id": "af53bfd5908b3049",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rearrange the following sentence to make the sentence more interesting.\n",
      "\n",
      "She left the party early\n",
      "Early, she left the party.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: wikipedia summary",
   "id": "204976b846ac7bfd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:05:36.959816162Z",
     "start_time": "2026-02-15T09:05:34.600935915Z"
    }
   },
   "cell_type": "code",
   "source": [
    "splits = load_dataset(\"jordiclive/wikipedia-summary-dataset\", split=\"train\").train_test_split(\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "ds_test = splits[\"test\"].select_columns([\"summary\"])\n",
    "ds_train = splits[\"train\"].select_columns([\"summary\"])"
   ],
   "id": "1ad7ca6881a27196",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:18:19.876991359Z",
     "start_time": "2026-02-15T09:10:10.661983241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_wiki(batch: LazyBatch):\n",
    "    eot = special_tokens[\"end_of_text\"]\n",
    "    results = [\n",
    "        tokenizer.encode(row + \"\\n\" + eot).ids\n",
    "        for row in batch[\"summary\"]\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test.map(\n",
    "    tokenize_wiki,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\").save_to_disk(\"tokenized_data/wiki_test\")\n",
    "\n",
    "ds_train.map(\n",
    "    tokenize_wiki,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\").save_to_disk(\"tokenized_data/wiki_train\")"
   ],
   "id": "4a89dd722a5e8202",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/775001 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8b41691c4bc4dabbcd00ea35e44607a"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/2 shards):   0%|          | 0/775001 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95cea5e9f93e47d992051b654c7a7884"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/6975006 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ec149a9dda14b7c96b3b68ba82dc2b3"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/13 shards):   0%|          | 0/6975006 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "832eace9f00a4c4fa0423dffbf405628"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:18:21.451896089Z",
     "start_time": "2026-02-15T09:18:20.141929985Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/wiki_test\"))",
   "id": "841d9728bc3695eb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category:Populated places in McPherson County, Nebraska\n",
      "McPherson\n",
      "\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: tiny stories",
   "id": "fd11bc77bf1c1bdf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:18:26.856609628Z",
     "start_time": "2026-02-15T09:18:21.468631568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_test = load_dataset(\"roneneldan/TinyStories\", split=\"validation\").select_columns([\"text\"])\n",
    "ds_train = load_dataset(\"roneneldan/TinyStories\", split=\"train\").select_columns([\"text\"])"
   ],
   "id": "af288c35ebda2064",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:22:29.474454650Z",
     "start_time": "2026-02-15T09:18:26.869001089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_stories(batch: LazyBatch):\n",
    "    eot = special_tokens[\"end_of_text\"]\n",
    "    results = [\n",
    "        tokenizer.encode(row + \"\\n\" + eot).ids\n",
    "        for row in batch[\"text\"]\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test.map(\n",
    "    tokenize_stories,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\").save_to_disk(\"tokenized_data/stories_test\")\n",
    "\n",
    "ds_train.map(\n",
    "    tokenize_stories,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\").save_to_disk(\"tokenized_data/stories_train\")"
   ],
   "id": "7f5714539b15204d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc5d0ba23a4148c2912b941731375c9f"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21990 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0907f5a54204100839c79aa1c60eeb8"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "893b7ec61e4743b8a3af2bb5eb19023e"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/8 shards):   0%|          | 0/2119719 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f43900b39e2b4365bfafb7db67171351"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:22:29.635800793Z",
     "start_time": "2026-02-15T09:22:29.494835952Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/stories_test\"))",
   "id": "37556459f04557e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spot. Spot saw the shiny car and said, \"Wow, Kitty, your car is so bright and clean!\" Kitty smiled and replied, \"Thank you, Spot. I polish it every day.\"\n",
      "\n",
      "After playing with the car, Kitty and Spot felt thirsty. They found a small pond with clear water. They drank the water and felt very happy. They played together all day and became best friends.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Dataset: tiny textbooks",
   "id": "197e0f793f9a78ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:22:34.214907807Z",
     "start_time": "2026-02-15T09:22:29.639295850Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds_test = load_dataset(\"nampdn-ai/tiny-textbooks\", split=\"test\").select_columns([\"textbook\"])\n",
    "ds_train = load_dataset(\"nampdn-ai/tiny-textbooks\", split=\"train\").select_columns([\"textbook\"])"
   ],
   "id": "cb8d24aab8e0144a",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:25:11.430200664Z",
     "start_time": "2026-02-15T09:22:34.217325744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tokenize_textbooks(batch: LazyBatch):\n",
    "    eot = special_tokens[\"end_of_text\"]\n",
    "    results = [\n",
    "        tokenizer.encode(row + \"\\n\" + eot).ids\n",
    "        for row in batch[\"textbook\"]\n",
    "    ]\n",
    "    return {\"tokens\": results}\n",
    "\n",
    "\n",
    "ds_test.map(\n",
    "    tokenize_textbooks,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\").save_to_disk(\"tokenized_data/textbooks_test\")\n",
    "\n",
    "ds_train.map(\n",
    "    tokenize_textbooks,\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=processes\n",
    ").select_columns(\"tokens\").save_to_disk(\"tokenized_data/textbooks_train\")"
   ],
   "id": "44ff5c4f946d9bea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/21000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88145e02a86d458984801e634018e6ea"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/21000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67949e4a61b94024a89a86ec2211bd76"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/399000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9815c09109241d39b2890acf588513c"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Saving the dataset (0/5 shards):   0%|          | 0/399000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "120ce18e68914d83816f22ac0189cebd"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-15T09:25:11.502000651Z",
     "start_time": "2026-02-15T09:25:11.437429638Z"
    }
   },
   "cell_type": "code",
   "source": "test_tokens(load_from_disk(\"tokenized_data/textbooks_test\"))",
   "id": "5a8d0b156694daa5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lesson: How to Analyze a Drama Series\n",
      "\n",
      "Introduction:\n",
      "In this lesson, we will learn how to analyze a drama series by breaking down its plot, characters, and themes. We will use \"Karelasyon\" as our example to demonstrate how to apply these analytical tools to a specific work.\n",
      "\n",
      "Section 1: Plot Analysis\n",
      "\n",
      "Plot refers to the events and conflicts that make up a story. In \"Karelasyon,\" the plot revolves around Carmen and Jess's relationship and how it affects Carmen's daughter, Kat-kat. \n",
      "\n",
      "1. What is the main conflict of the story?\n",
      "The main conflict is Carmen's hope that Jess will treat Kat-kat like his own daughter.\n",
      "\n",
      "2. How does the story develop this conflict?\n",
      "The story develops this conflict through Carmen and Jess's interactions with Kat-kat, showing how their relationship affects her.\n",
      "\n",
      "3. What is the resolution of the story?\n",
      "The resolution is not explicitly stated, but it can be inferred that the story ends with Carmen and Jess continuing to live together and care for Kat-kat.\n",
      "\n",
      "Section 2: Character Analysis\n",
      "\n",
      "Character analysis involves examining the traits, motivations, and actions of the characters in a story. In \"Karelasyon,\" the main characters are Carmen, Jess, and Kat-kat.\n",
      "\n",
      "1. What are Carmen's traits?\n",
      "Carmen is loving, caring, and protective of her daughter, Kat-kat.\n",
      "\n",
      "2. What are Jess's traits?\n",
      "Jess is kind, compassionate, and willing to do anything for the woman he loves, Carmen.\n",
      "\n",
      "3. What is Kat-kat's role in the story?\n",
      "Kat-kat is the child caught in the middle of her mother's relationship with Jess. She is used as a way to show the impact of their relationship on others.\n",
      "\n",
      "Section 3: Theme Analysis\n",
      "\n",
      "Theme analysis involves identifying the underlying messages or ideas conveyed by a story. In \"Karelasyon,\" the themes are love, family, and responsibility.\n",
      "\n",
      "1. What is the theme of the story?\n",
      "The theme of the story is the complexity of blending families and the challenges that come with it.\n",
      "\n",
      "2. How does the story convey this theme?\n",
      "The story conveys this theme through the interactions between Carmen, Jess, and Kat-kat, showing the difficulties that arise when two families combine.\n",
      "\n",
      "Conclusion:\n",
      "In this lesson, we learned how to analyze a drama series by examining its plot, characters, and themes. By applying these analytical tools to \"Karelasyon,\" we were able to identify the main conflict, character traits, and underlying themes of the story. This skill can be applied to other works of literature or film to deepen our understanding and appreciation of the art form.\n",
      "\n",
      "Glossary:\n",
      "- Plot: The events and conflicts that make up a story.\n",
      "- Character: A person in a story, often defined by their traits and actions.\n",
      "- Theme: The underlying message or idea conveyed by a story.\n",
      "\n",
      "[Note: This lesson is intended for primary through high school students. The content may need to be simplified or expanded upon depending on the age group.]\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
