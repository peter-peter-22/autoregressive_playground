{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:06.241163365Z",
     "start_time": "2026-02-17T17:51:06.203551548Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "torch.manual_seed(42)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:06.303458123Z",
     "start_time": "2026-02-17T17:51:06.263294690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def tensor_stats(name, t):\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  mean: {t.mean().item():.6f}\")\n",
    "    print(f\"  std:  {t.std().item():.6f}\")\n",
    "    print(f\"  min:  {t.min().item():.6f}\")\n",
    "    print(f\"  max:  {t.max().item():.6f}\")\n",
    "    print()"
   ],
   "id": "d614307f91ccd2ef",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:06.338652741Z",
     "start_time": "2026-02-17T17:51:06.305764430Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TinyLM(nn.Module):\n",
    "    def __init__(self, vocab_size=24000, d_model=256, tie_weights=False, init_mode=\"default\", std=0.02):\n",
    "        super().__init__()\n",
    "\n",
    "        self.std=std\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.head = nn.Linear(d_model, vocab_size, bias=False)\n",
    "\n",
    "        # Optional custom GPT-style init\n",
    "        if init_mode == \"gpt\":\n",
    "            self.apply(self._init_weights)\n",
    "\n",
    "        # Optional tying\n",
    "        if tie_weights:\n",
    "            self.head.weight = self.embedding.weight\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=self.std)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            nn.init.normal_(module.weight, mean=0.0, std=self.std)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        x = self.embedding(idx)\n",
    "        logits = self.head(x)\n",
    "        return logits\n"
   ],
   "id": "add839694ae51893",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:06.385693050Z",
     "start_time": "2026-02-17T17:51:06.361443716Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_experiment(init_mode=\"default\", tie_weights=False,std=0.02):\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Init: {init_mode} | Tied: {tie_weights}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    vocab_size = 24000\n",
    "    d_model = 256\n",
    "    batch = 16\n",
    "    seq_len = 32\n",
    "\n",
    "    model = TinyLM(\n",
    "        vocab_size=vocab_size,\n",
    "        d_model=d_model,\n",
    "        tie_weights=tie_weights,\n",
    "        init_mode=init_mode,\n",
    "        std=std\n",
    "    ).to(device)\n",
    "\n",
    "    # Inspect weight stats\n",
    "    tensor_stats(\"Embedding weight\", model.embedding.weight)\n",
    "    tensor_stats(\"Head weight\", model.head.weight)\n",
    "\n",
    "    # Random tokens\n",
    "    idx = torch.randint(0, vocab_size, (batch, seq_len)).to(device)\n",
    "    targets = torch.randint(0, vocab_size, (batch, seq_len)).to(device)\n",
    "\n",
    "    logits = model(idx)\n",
    "\n",
    "    tensor_stats(\"Logits\", logits)\n",
    "\n",
    "    loss = F.cross_entropy(\n",
    "        logits.view(-1, vocab_size),\n",
    "        targets.view(-1)\n",
    "    )\n",
    "\n",
    "    print(f\"Initial cross-entropy loss: {loss.item():.4f}\")"
   ],
   "id": "b23c41f4e5b96c52",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:06.756744082Z",
     "start_time": "2026-02-17T17:51:06.388408305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1️⃣ Default init, no tying\n",
    "run_experiment(init_mode=\"default\", tie_weights=False)"
   ],
   "id": "64066db04935b968",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Init: default | Tied: False\n",
      "============================================================\n",
      "Embedding weight:\n",
      "  mean: -0.000112\n",
      "  std:  0.999893\n",
      "  min:  -4.866143\n",
      "  max:  5.105051\n",
      "\n",
      "Head weight:\n",
      "  mean: 0.000013\n",
      "  std:  0.036081\n",
      "  min:  -0.062500\n",
      "  max:  0.062500\n",
      "\n",
      "Logits:\n",
      "  mean: -0.000117\n",
      "  std:  0.577106\n",
      "  min:  -2.990200\n",
      "  max:  2.994646\n",
      "\n",
      "Initial cross-entropy loss: 10.2468\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:07.113215465Z",
     "start_time": "2026-02-17T17:51:06.760407620Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2️⃣ Default init, tied\n",
    "run_experiment(init_mode=\"default\", tie_weights=True)"
   ],
   "id": "56846d0876cb561c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Init: default | Tied: True\n",
      "============================================================\n",
      "Embedding weight:\n",
      "  mean: 0.000253\n",
      "  std:  0.999532\n",
      "  min:  -4.943582\n",
      "  max:  5.067348\n",
      "\n",
      "Head weight:\n",
      "  mean: 0.000253\n",
      "  std:  0.999532\n",
      "  min:  -4.943582\n",
      "  max:  5.067348\n",
      "\n",
      "Logits:\n",
      "  mean: 0.018177\n",
      "  std:  16.075432\n",
      "  min:  -83.414558\n",
      "  max:  322.034058\n",
      "\n",
      "Initial cross-entropy loss: 256.9717\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:07.510798222Z",
     "start_time": "2026-02-17T17:51:07.148666726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 3️⃣ GPT init, no tying\n",
    "run_experiment(init_mode=\"gpt\", tie_weights=False)"
   ],
   "id": "39b7c071fadde79c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Init: gpt | Tied: False\n",
      "============================================================\n",
      "Embedding weight:\n",
      "  mean: -0.000001\n",
      "  std:  0.020006\n",
      "  min:  -0.099682\n",
      "  max:  0.104341\n",
      "\n",
      "Head weight:\n",
      "  mean: 0.000005\n",
      "  std:  0.020001\n",
      "  min:  -0.099009\n",
      "  max:  0.106684\n",
      "\n",
      "Logits:\n",
      "  mean: 0.000000\n",
      "  std:  0.006390\n",
      "  min:  -0.032634\n",
      "  max:  0.034525\n",
      "\n",
      "Initial cross-entropy loss: 10.0852\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:07.878403517Z",
     "start_time": "2026-02-17T17:51:07.522367385Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4️⃣ GPT init, tied\n",
    "run_experiment(init_mode=\"gpt\", tie_weights=True)"
   ],
   "id": "19584cf2941735d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Init: gpt | Tied: True\n",
      "============================================================\n",
      "Embedding weight:\n",
      "  mean: -0.000017\n",
      "  std:  0.019997\n",
      "  min:  -0.098965\n",
      "  max:  0.099343\n",
      "\n",
      "Head weight:\n",
      "  mean: -0.000017\n",
      "  std:  0.019997\n",
      "  min:  -0.098965\n",
      "  max:  0.099343\n",
      "\n",
      "Logits:\n",
      "  mean: 0.000006\n",
      "  std:  0.006420\n",
      "  min:  -0.033634\n",
      "  max:  0.126838\n",
      "\n",
      "Initial cross-entropy loss: 10.0858\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-17T17:51:08.283626779Z",
     "start_time": "2026-02-17T17:51:07.897269310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 4️⃣ GPT init, tied, big weights\n",
    "run_experiment(init_mode=\"gpt\", tie_weights=True, std=0.2)"
   ],
   "id": "5c0ab89b85b30139",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Init: gpt | Tied: True\n",
      "============================================================\n",
      "Embedding weight:\n",
      "  mean: -0.000049\n",
      "  std:  0.199923\n",
      "  min:  -1.093782\n",
      "  max:  1.081741\n",
      "\n",
      "Head weight:\n",
      "  mean: -0.000049\n",
      "  std:  0.199923\n",
      "  min:  -1.093782\n",
      "  max:  1.081741\n",
      "\n",
      "Logits:\n",
      "  mean: 0.000782\n",
      "  std:  0.641566\n",
      "  min:  -3.383894\n",
      "  max:  13.013767\n",
      "\n",
      "Initial cross-entropy loss: 11.0418\n"
     ]
    }
   ],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
