{
 "cells": [
  {
   "cell_type": "code",
   "id": "39f49c5833de57aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:13.471165129Z",
     "start_time": "2026-02-23T08:05:13.349211546Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk, Dataset\n",
    "from millify import millify\n",
    "\n",
    "from chat_template import chat_template\n",
    "from learning_metrics import get_grad_metrics\n",
    "from learning_metrics import get_weight_metrics\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "dbe19c1cdb7088f1",
   "metadata": {},
   "source": [
    "Mode settings\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "67cf94c976797ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:13.716409650Z",
     "start_time": "2026-02-23T08:05:13.545822129Z"
    }
   },
   "source": [
    "minified = True\n",
    "colab = False\n",
    "thunder = False\n",
    "checkpoint: int | None = None\n",
    "compile = True"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "4c7e0486169f9ddf",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "id": "aeae42b7d36357bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:14.406499432Z",
     "start_time": "2026-02-23T08:05:13.820131403Z"
    }
   },
   "source": [
    "if colab:\n",
    "    data_dir = \"/content/drive/MyDrive/tokenized_data\"\n",
    "    checkpoint_dir = \"/content/drive/MyDrive/instruction_checkpoints\"\n",
    "elif thunder:\n",
    "    os.makedirs(\"output/instruction_checkpoints\", exist_ok=True)\n",
    "    # if not os.path.exists(\"tokenized_data/train.bin\"):\n",
    "    #     gdown.download(id=\"15t3259RbsF772b35aaZGouGwQopFAX96\",output=\"tokenized_data/train.bin\")\n",
    "    # if not os.path.exists(\"tokenized_data/test.bin\"):\n",
    "    #     gdown.download(id=\"1rE_MOBhBPQGUuhYmevNZOFj-LMBWkLFD\",output=\"tokenized_data/test.bin\")\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"output/instruction_checkpoints\"\n",
    "else:\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"instruction_checkpoints\"\n",
    "info_dir = checkpoint_dir + \"/info\"\n",
    "state_dir = checkpoint_dir + \"/state\"\n",
    "train_ds_name = data_dir + \"/train_chats\"\n",
    "test_ds_name = data_dir + \"/test_chats\""
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "276f1e2e08b01b20",
   "metadata": {},
   "source": [
    "General settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d4c17ce894ef249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:15.598096398Z",
     "start_time": "2026-02-23T08:05:14.941392626Z"
    }
   },
   "source": [
    "if not minified and colab:\n",
    "    if colab:\n",
    "        # Training data\n",
    "        block_size = ModelSettings.max_context_length\n",
    "        batch_size = 8\n",
    "\n",
    "        # Learning\n",
    "        max_iters = 6_000\n",
    "        learning_rate = 1e-5\n",
    "        eval_iters = 30\n",
    "        eval_interval = 300\n",
    "        grad_clip = 1.0\n",
    "        log_metrics_interval = 30\n",
    "        log_text = 100\n",
    "    else:\n",
    "        # Training data\n",
    "        block_size = ModelSettings.max_context_length\n",
    "        batch_size = 32\n",
    "\n",
    "        # Learning\n",
    "        max_iters = 1_500\n",
    "        learning_rate = 5e-5\n",
    "        eval_iters = 30\n",
    "        eval_interval = 150\n",
    "        grad_clip = 1.0\n",
    "        log_metrics_interval = 30\n",
    "        log_text = 100\n",
    "else:\n",
    "    # Training data\n",
    "    block_size = 64\n",
    "    batch_size = 8\n",
    "\n",
    "    # Learning\n",
    "    max_iters = 500\n",
    "    learning_rate = 1e-4\n",
    "    eval_iters = 10\n",
    "    eval_interval = 20\n",
    "    grad_clip = 1.0\n",
    "    log_metrics_interval = 2\n",
    "    log_text = 50"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "51b16ef728a43388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:16.593478066Z",
     "start_time": "2026-02-23T08:05:16.076772584Z"
    }
   },
   "source": [
    "print(max_iters * batch_size / 9_500)\n",
    "print(millify(max_iters * batch_size * block_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42105263157894735\n",
      "256k\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:17.642004076Z",
     "start_time": "2026-02-23T08:05:16.965481198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers.tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "pad_id = tokenizer.token_to_id(special_tokens[\"pad\"])"
   ],
   "id": "82a7bd6e9430b08d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "71caaf7a7a523d74",
   "metadata": {},
   "source": [
    "Hardware settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4068dad6e64b371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:18.157346737Z",
     "start_time": "2026-02-23T08:05:17.909275319Z"
    }
   },
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True  # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True  # allow tf32 on cudnn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "autocast_enabled = device_type == \"cuda\"\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "b2238c5052b49fca",
   "metadata": {},
   "source": [
    "Training data stream"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:18.306851154Z",
     "start_time": "2026-02-23T08:05:18.246610674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infinite_iterator(ds: Dataset):\n",
    "    n = 0\n",
    "    while True:\n",
    "        iterator = iter(ds.shuffle(n))\n",
    "        n+=1\n",
    "        for el in iterator:\n",
    "            yield el"
   ],
   "id": "36aa087fd28cc248",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:18.443483889Z",
     "start_time": "2026-02-23T08:05:18.334339224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ignore_index = -100\n",
    "if not minified:\n",
    "    ds_test = infinite_iterator(load_from_disk(test_ds_name))\n",
    "    ds_train = infinite_iterator(load_from_disk(train_ds_name))\n",
    "else:\n",
    "    ds_test = infinite_iterator(load_from_disk(test_ds_name).take(100))\n",
    "    ds_train = infinite_iterator(load_from_disk(test_ds_name).take(10))\n",
    "\n",
    "\n",
    "def prepare_chat(chat, target_size, pad_element):\n",
    "    token_ids = chat[\"tokens\"]\n",
    "    assistant_mask = chat[\"assistant_mask\"]\n",
    "    length = len(token_ids)\n",
    "    # truncate to target size\n",
    "    if length > target_size:\n",
    "        trim = length - target_size\n",
    "        return token_ids[trim:], assistant_mask[trim:]\n",
    "    # pad to target size\n",
    "    if length < target_size:\n",
    "        padding = target_size - length\n",
    "        return token_ids + [pad_element] * padding, assistant_mask + [False] * padding\n",
    "    # unchanged\n",
    "    return token_ids, assistant_mask\n",
    "\n",
    "\n",
    "def apply_mask(tokens, assistant_mask):\n",
    "    return [\n",
    "        t if assistant_mask[i] else ignore_index\n",
    "        for i, t in enumerate(tokens)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    iterator = ds_train if split == 'train' else ds_test\n",
    "    batch = [next(iterator) for _ in range(batch_size)]\n",
    "    longest_chat = max([len(row[\"tokens\"]) for row in batch])\n",
    "    target_length = min(longest_chat, block_size + 1)\n",
    "    chats = [prepare_chat(chat, target_length, pad_id) for chat in batch]\n",
    "    x = torch.stack([torch.tensor(tokens[0:target_length - 1], dtype=torch.long) for tokens, mask in chats])\n",
    "    y = torch.stack(\n",
    "        [torch.tensor(apply_mask(tokens[1:target_length], mask[1:target_length]), dtype=torch.long) for tokens, mask in\n",
    "         chats])\n",
    "    if device == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ],
   "id": "ddc05c0fccf1c81b",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:18.712836225Z",
     "start_time": "2026-02-23T08:05:18.496167548Z"
    }
   },
   "cell_type": "code",
   "source": "get_batch(split=\"test\")[0].shape",
   "id": "16cb181844baceb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "4c9bf0633d5a4597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:18.941027580Z",
     "start_time": "2026-02-23T08:05:18.819372031Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "8594f48b269e2a2f",
   "metadata": {},
   "source": [
    "Scaler for FP16"
   ]
  },
  {
   "cell_type": "code",
   "id": "756fe3809acc0c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:18.981839474Z",
     "start_time": "2026-02-23T08:05:18.955642503Z"
    }
   },
   "source": [
    "scaler = torch.amp.GradScaler(device_type)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "32532e7c9d6b345",
   "metadata": {},
   "source": [
    "Model settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "d529ab02a58a4ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:19.400422826Z",
     "start_time": "2026-02-23T08:05:18.986449887Z"
    }
   },
   "source": [
    "from model import ChatModel\n",
    "from settings import ModelSettings\n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if compile:\n",
    "    model = torch.compile(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "dc195a20418e5df9",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8dc1093f08e8628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:19.508369869Z",
     "start_time": "2026-02-23T08:05:19.483031781Z"
    }
   },
   "source": [
    "from optimizer import get_optim_groups\n",
    "\n",
    "optim_groups = get_optim_groups(model)\n",
    "\n",
    "# apply dynamic learning rate to the optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optim_groups,\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-8\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "3dc19bb659d08265",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:19.542801828Z",
     "start_time": "2026-02-23T08:05:19.514697858Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 35,
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50):\n",
    "    idx = torch.tensor([tokenizer.encode(start, add_special_tokens=False).ids], device=device, dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "id": "fa87a85c5d97f75f"
  },
  {
   "cell_type": "markdown",
   "id": "24e3028ea893d325",
   "metadata": {},
   "source": [
    "Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "id": "47f3bb6eba858215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:19.573653495Z",
     "start_time": "2026-02-23T08:05:19.547245591Z"
    }
   },
   "source": [
    "os.makedirs(info_dir, exist_ok=True)\n",
    "os.makedirs(state_dir, exist_ok=True)\n",
    "\n",
    "messages=[{\n",
    "    \"role\":\"user\",\n",
    "    \"content\":\"Write one paragraph about the Tlachihualtepetl pyramid. Keep it at or below 15 sentences. Include its size and when it was built. Also, include any aspects of worship it had. Include aspects of its more recent history, too. Name at least one specific year.\"\n",
    "}]\n",
    "test_text=chat_template(messages,add_generation_token=True)\n",
    "\n",
    "def save_checkpoint(\n",
    "        step,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scaler,\n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        metric_logs\n",
    "):\n",
    "    state = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if scaler else None,\n",
    "    }\n",
    "\n",
    "    info = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"time\": datetime.now().isoformat(),\n",
    "        \"block_size\": block_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"eval_interval\": eval_interval,\n",
    "        \"step\": step,\n",
    "        \"text\": generate(model, text, log_text),\n",
    "        \"metrics\": json.dumps(metric_logs)\n",
    "    }\n",
    "\n",
    "    state_path = f\"{state_dir}/{step:05d}.pt\"\n",
    "    info_path = f\"{info_dir}/{step:05d}.pt\"\n",
    "\n",
    "    torch.save(state, state_path)\n",
    "    torch.save(info, info_path)\n",
    "\n",
    "    return state_path, info_path"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load pre-training",
   "id": "cc2939edff54e33a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:19.945262004Z",
     "start_time": "2026-02-23T08:05:19.577319879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if checkpoint is None:\n",
    "    state = torch.load(f\"pre_checkpoints/state/00999.pt\")\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(\"Loaded pre-training\")"
   ],
   "id": "21920696f94dfc9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-training\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "2ea15b7d65829578",
   "metadata": {},
   "source": [
    "Load training state"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cf313bfd2550641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:20.110783293Z",
     "start_time": "2026-02-23T08:05:20.082513927Z"
    }
   },
   "source": [
    "def load_checkpoint(step: int):\n",
    "    state = torch.load(f\"{state_dir}/{step:05d}.pt\")\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(f\"Loaded checkpoint {step}\")\n",
    "\n",
    "\n",
    "if checkpoint is not None:\n",
    "    load_checkpoint(checkpoint)"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "81f9caa1faa59dcd",
   "metadata": {},
   "source": [
    "Clean up old checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "id": "39f4318ddec2db9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:05:20.236138669Z",
     "start_time": "2026-02-23T08:05:20.113227866Z"
    }
   },
   "source": [
    "from checkpoint_cleaner import CheckpointCleaner\n",
    "\n",
    "keep_progress = [0.5, 0.7, 0.8, 0.9]\n",
    "preserve_checkpoints = []\n",
    "i = 0\n",
    "last_keep = 0\n",
    "while True:\n",
    "    i += eval_interval\n",
    "    progress = i / max_iters\n",
    "    target_progress = keep_progress[last_keep]\n",
    "    if progress > target_progress:\n",
    "        state_path = f\"{state_dir}/{i:05d}.pt\"\n",
    "        preserve_checkpoints.append(state_path)\n",
    "        last_keep += 1\n",
    "        if last_keep == len(keep_progress):\n",
    "            break\n",
    "    if i >= max_iters:\n",
    "        break\n",
    "\n",
    "checkpoint_cleaner = CheckpointCleaner(3, preserve_checkpoints)\n",
    "preserve_checkpoints"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instruction_checkpoints/state/00260.pt',\n",
       " 'instruction_checkpoints/state/00360.pt',\n",
       " 'instruction_checkpoints/state/00420.pt',\n",
       " 'instruction_checkpoints/state/00460.pt']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "6b2775c2e3339206",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "198d433f585502b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:08:20.368704185Z",
     "start_time": "2026-02-23T08:05:20.256150220Z"
    }
   },
   "source": [
    "from system_metrics import get_system_metrics\n",
    "\n",
    "metric_logs = []\n",
    "\n",
    "for step in range(checkpoint or 0, max_iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    if autocast_enabled:\n",
    "        with torch.amp.autocast(dtype=torch.float16, device_type=device_type):\n",
    "            logits, loss = model(xb, yb)\n",
    "    else:\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "    # exit if the loss is invalid\n",
    "    if not torch.isfinite(loss):\n",
    "        raise Exception(\"Non-finite loss detected.\")\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "\n",
    "    if step % log_metrics_interval == 0:\n",
    "        total_norm, max_grad = get_grad_metrics(model)\n",
    "        max_weight, total_weight_norm = get_weight_metrics(model)\n",
    "        metric_logs.append({\n",
    "            \"gradient\": {\n",
    "                \"total_norm\": total_norm,\n",
    "                \"max_grad\": max_grad,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"max_weight\": max_weight,\n",
    "                \"total_weight_norm\": total_weight_norm,\n",
    "            },\n",
    "            \"system\": get_system_metrics(),\n",
    "            \"current_loss\": loss.item()\n",
    "        })\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    if step % eval_interval == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        state_path, info_path = save_checkpoint(\n",
    "            step=step,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            train_loss=losses[\"train\"],\n",
    "            val_loss=losses[\"val\"],\n",
    "            metric_logs=metric_logs\n",
    "        )\n",
    "        checkpoint_cleaner.step(state_path)\n",
    "        metric_logs = []\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 4.9578, val loss 4.6990\n",
      "step 20: train loss 3.7160, val loss 4.8096\n",
      "step 40: train loss 2.5511, val loss 4.9725\n",
      "step 60: train loss 1.6153, val loss 5.1776\n",
      "Removed checkpoint instruction_checkpoints/state/00000.pt\n",
      "step 80: train loss 0.9578, val loss 5.5123\n",
      "Removed checkpoint instruction_checkpoints/state/00020.pt\n",
      "step 100: train loss 0.5582, val loss 5.6766\n",
      "Removed checkpoint instruction_checkpoints/state/00040.pt\n",
      "step 120: train loss 0.3000, val loss 5.7706\n",
      "Removed checkpoint instruction_checkpoints/state/00060.pt\n",
      "step 140: train loss 0.1614, val loss 6.0380\n",
      "Removed checkpoint instruction_checkpoints/state/00080.pt\n",
      "step 160: train loss 0.0881, val loss 5.9902\n",
      "Removed checkpoint instruction_checkpoints/state/00100.pt\n",
      "step 180: train loss 0.0494, val loss 6.3471\n",
      "Removed checkpoint instruction_checkpoints/state/00120.pt\n",
      "step 200: train loss 0.0314, val loss 6.5015\n",
      "Removed checkpoint instruction_checkpoints/state/00140.pt\n",
      "step 220: train loss 0.0225, val loss 6.6690\n",
      "Removed checkpoint instruction_checkpoints/state/00160.pt\n",
      "step 240: train loss 0.0140, val loss 6.5256\n",
      "Removed checkpoint instruction_checkpoints/state/00180.pt\n",
      "step 260: train loss 0.0090, val loss 7.1131\n",
      "Removed checkpoint instruction_checkpoints/state/00200.pt\n",
      "step 280: train loss 0.0059, val loss 6.8258\n",
      "Removed checkpoint instruction_checkpoints/state/00220.pt\n",
      "step 300: train loss 0.0038, val loss 7.1268\n",
      "Removed checkpoint instruction_checkpoints/state/00240.pt\n",
      "step 320: train loss 0.0025, val loss 7.4827\n",
      "Preserving checkpoint instruction_checkpoints/state/00260.pt\n",
      "step 340: train loss 0.0016, val loss 7.5510\n",
      "Removed checkpoint instruction_checkpoints/state/00280.pt\n",
      "step 360: train loss 0.0131, val loss 7.3901\n",
      "Removed checkpoint instruction_checkpoints/state/00300.pt\n",
      "step 380: train loss 0.0031, val loss 7.6851\n",
      "Removed checkpoint instruction_checkpoints/state/00320.pt\n",
      "step 400: train loss 0.0015, val loss 7.8477\n",
      "Removed checkpoint instruction_checkpoints/state/00340.pt\n",
      "step 420: train loss 0.0010, val loss 8.1713\n",
      "Preserving checkpoint instruction_checkpoints/state/00360.pt\n",
      "step 440: train loss 0.0007, val loss 7.3006\n",
      "Removed checkpoint instruction_checkpoints/state/00380.pt\n",
      "step 460: train loss 0.0006, val loss 7.8019\n",
      "Removed checkpoint instruction_checkpoints/state/00400.pt\n",
      "step 480: train loss 0.0004, val loss 8.4380\n",
      "Preserving checkpoint instruction_checkpoints/state/00420.pt\n",
      "step 499: train loss 0.0003, val loss 8.0627\n",
      "Removed checkpoint instruction_checkpoints/state/00440.pt\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "1173b07565d315a4",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b89a73b965f9742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T08:11:33.470202849Z",
     "start_time": "2026-02-23T08:11:33.099234600Z"
    }
   },
   "source": "print(generate(model, test_text,20))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " to dinner with some friends and then seeing a movie at the theatre.\n",
      "How fun!\n",
      "7. More on Plin: Sweden and e World by London\n",
      "7. Luft in touch\n"
     ]
    }
   ],
   "execution_count": 54
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
