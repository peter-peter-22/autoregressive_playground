{
 "cells": [
  {
   "cell_type": "code",
   "id": "39f49c5833de57aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.032187541Z",
     "start_time": "2026-02-22T23:19:48.013569092Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk, Dataset\n",
    "from millify import millify\n",
    "\n",
    "from learning_metrics import get_grad_metrics\n",
    "from learning_metrics import get_weight_metrics\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "dbe19c1cdb7088f1",
   "metadata": {},
   "source": [
    "Mode settings\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "67cf94c976797ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.047426659Z",
     "start_time": "2026-02-22T23:19:48.033578615Z"
    }
   },
   "source": [
    "minified = True\n",
    "colab = False\n",
    "thunder = False\n",
    "checkpoint: int | None = None\n",
    "compile = True"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "markdown",
   "id": "4c7e0486169f9ddf",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "id": "aeae42b7d36357bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.063487408Z",
     "start_time": "2026-02-22T23:19:48.048759702Z"
    }
   },
   "source": [
    "if colab:\n",
    "    data_dir = \"/content/drive/MyDrive/tokenized_data\"\n",
    "    checkpoint_dir = \"/content/drive/MyDrive/instruction_checkpoints\"\n",
    "elif thunder:\n",
    "    os.makedirs(\"output/instruction_checkpoints\", exist_ok=True)\n",
    "    # if not os.path.exists(\"tokenized_data/train.bin\"):\n",
    "    #     gdown.download(id=\"15t3259RbsF772b35aaZGouGwQopFAX96\",output=\"tokenized_data/train.bin\")\n",
    "    # if not os.path.exists(\"tokenized_data/test.bin\"):\n",
    "    #     gdown.download(id=\"1rE_MOBhBPQGUuhYmevNZOFj-LMBWkLFD\",output=\"tokenized_data/test.bin\")\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"output/instruction_checkpoints\"\n",
    "else:\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"instruction_checkpoints\"\n",
    "info_dir = checkpoint_dir + \"/info\"\n",
    "state_dir = checkpoint_dir + \"/state\"\n",
    "train_ds_name = data_dir + \"/train_chats\"\n",
    "test_ds_name = data_dir + \"/test_chats\""
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "276f1e2e08b01b20",
   "metadata": {},
   "source": [
    "General settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d4c17ce894ef249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.095802414Z",
     "start_time": "2026-02-22T23:19:48.075221861Z"
    }
   },
   "source": [
    "if not minified:\n",
    "    # Training data\n",
    "    block_size = ModelSettings.max_context_length\n",
    "    batch_size = 32\n",
    "\n",
    "    # Learning\n",
    "    max_iters = 1_500\n",
    "    learning_rate = 1e-4\n",
    "    eval_iters = 100\n",
    "    eval_interval = 15\n",
    "    grad_clip = 1.0\n",
    "    log_metrics_interval = 30\n",
    "    log_text = 100\n",
    "else:\n",
    "    # Training data\n",
    "    block_size = 64\n",
    "    batch_size = 8\n",
    "\n",
    "    # Learning\n",
    "    max_iters = 1000\n",
    "    learning_rate = 1e-4\n",
    "    eval_iters = 10\n",
    "    eval_interval = 20\n",
    "    grad_clip = 1.0\n",
    "    log_metrics_interval = 2\n",
    "    log_text = 50"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "51b16ef728a43388",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.143466456Z",
     "start_time": "2026-02-22T23:19:48.107470232Z"
    }
   },
   "source": [
    "print(max_iters * batch_size / 9_500)\n",
    "print(millify(max_iters * batch_size * block_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8421052631578947\n",
      "512k\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.218030302Z",
     "start_time": "2026-02-22T23:19:48.145134906Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers.tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "pad_id = tokenizer.token_to_id(special_tokens[\"pad\"])"
   ],
   "id": "82a7bd6e9430b08d",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "71caaf7a7a523d74",
   "metadata": {},
   "source": [
    "Hardware settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4068dad6e64b371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.240817766Z",
     "start_time": "2026-02-22T23:19:48.220658869Z"
    }
   },
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True  # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True  # allow tf32 on cudnn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "autocast_enabled = device_type == \"cuda\"\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "b2238c5052b49fca",
   "metadata": {},
   "source": [
    "Training data stream"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.249463707Z",
     "start_time": "2026-02-22T23:19:48.241594124Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infinite_iterator(ds: Dataset):\n",
    "    while True:\n",
    "        iterator = iter(ds.shuffle())\n",
    "        for el in iterator:\n",
    "            yield el"
   ],
   "id": "36aa087fd28cc248",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.267451494Z",
     "start_time": "2026-02-22T23:19:48.250635435Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ignore_index = -100\n",
    "ds_test = infinite_iterator(load_from_disk(test_ds_name))\n",
    "ds_train = infinite_iterator(load_from_disk(train_ds_name))\n",
    "\n",
    "\n",
    "def prepare_chat(chat, target_size, pad_element):\n",
    "    token_ids = chat[\"tokens\"]\n",
    "    assistant_mask = chat[\"assistant_mask\"]\n",
    "    length = len(token_ids)\n",
    "    # truncate to target size\n",
    "    if length > target_size:\n",
    "        trim = length - target_size\n",
    "        return token_ids[trim:], assistant_mask[trim:]\n",
    "    # pad to target size\n",
    "    if length < target_size:\n",
    "        padding = target_size - length\n",
    "        return token_ids + [pad_element] * padding, assistant_mask + [False] * padding\n",
    "    # unchanged\n",
    "    return token_ids, assistant_mask\n",
    "\n",
    "\n",
    "def apply_mask(tokens, assistant_mask):\n",
    "    return [\n",
    "        t if assistant_mask[i] else ignore_index\n",
    "        for i, t in enumerate(tokens)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    iterator = ds_train if split == 'train' else ds_test\n",
    "    batch = [next(iterator) for _ in range(batch_size)]\n",
    "    longest_chat = max([len(row[\"tokens\"]) for row in batch])\n",
    "    target_length = min(longest_chat, block_size + 1)\n",
    "    chats = [prepare_chat(chat, target_length, pad_id) for chat in batch]\n",
    "    x = torch.stack([torch.tensor(tokens[0:target_length - 1], dtype=torch.long) for tokens, mask in chats])\n",
    "    y = torch.stack(\n",
    "        [torch.tensor(apply_mask(tokens[1:target_length], mask[1:target_length]), dtype=torch.long) for tokens, mask in\n",
    "         chats])\n",
    "    if device == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ],
   "id": "ddc05c0fccf1c81b",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.292189851Z",
     "start_time": "2026-02-22T23:19:48.269731966Z"
    }
   },
   "cell_type": "code",
   "source": "get_batch(split=\"test\")[0].shape",
   "id": "16cb181844baceb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "4c9bf0633d5a4597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.300535662Z",
     "start_time": "2026-02-22T23:19:48.292942352Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "id": "8594f48b269e2a2f",
   "metadata": {},
   "source": [
    "Scaler for FP16"
   ]
  },
  {
   "cell_type": "code",
   "id": "756fe3809acc0c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.310759680Z",
     "start_time": "2026-02-22T23:19:48.301374617Z"
    }
   },
   "source": [
    "scaler = torch.amp.GradScaler(device_type)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "32532e7c9d6b345",
   "metadata": {},
   "source": [
    "Model settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "d529ab02a58a4ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.363583540Z",
     "start_time": "2026-02-22T23:19:48.311579014Z"
    }
   },
   "source": [
    "from model import ChatModel\n",
    "from settings import ModelSettings\n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if compile:\n",
    "    model = torch.compile(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "dc195a20418e5df9",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8dc1093f08e8628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.370503098Z",
     "start_time": "2026-02-22T23:19:48.364197268Z"
    }
   },
   "source": [
    "from optimizer import get_optim_groups\n",
    "\n",
    "optim_groups = get_optim_groups(model)\n",
    "\n",
    "# apply dynamic learning rate to the optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optim_groups,\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-8\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "markdown",
   "id": "3dc19bb659d08265",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "cell_type": "code",
   "id": "fa87a85c5d97f75f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.381571265Z",
     "start_time": "2026-02-22T23:19:48.371281816Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50):\n",
    "    idx = torch.tensor([tokenizer.encode(start, add_special_tokens=False).ids], device=device, dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "24e3028ea893d325",
   "metadata": {},
   "source": [
    "Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "id": "47f3bb6eba858215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.394189630Z",
     "start_time": "2026-02-22T23:19:48.383066286Z"
    }
   },
   "source": [
    "os.makedirs(info_dir, exist_ok=True)\n",
    "os.makedirs(state_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "def save_checkpoint(\n",
    "        step,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scaler,\n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        metric_logs\n",
    "):\n",
    "    state = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if scaler else None,\n",
    "    }\n",
    "\n",
    "    info = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"time\": datetime.now().isoformat(),\n",
    "        \"block_size\": block_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"eval_interval\": eval_interval,\n",
    "        \"step\": step,\n",
    "        \"text\": generate(model, \"Once upon a time\", log_text),\n",
    "        \"metrics\": json.dumps(metric_logs)\n",
    "    }\n",
    "\n",
    "    state_path = f\"{state_dir}/{step:05d}.pt\"\n",
    "    info_path = f\"{info_dir}/{step:05d}.pt\"\n",
    "\n",
    "    torch.save(state, state_path)\n",
    "    torch.save(info, info_path)\n",
    "\n",
    "    return state_path, info_path"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "2ea15b7d65829578",
   "metadata": {},
   "source": [
    "Load training state"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cf313bfd2550641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.405466078Z",
     "start_time": "2026-02-22T23:19:48.395689831Z"
    }
   },
   "source": [
    "def load_checkpoint(step: int):\n",
    "    state = torch.load(f\"{state_dir}/{step:05d}.pt\")\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(f\"Loaded checkpoint {step}\")\n",
    "\n",
    "\n",
    "if checkpoint is not None:\n",
    "    load_checkpoint(checkpoint)"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "81f9caa1faa59dcd",
   "metadata": {},
   "source": [
    "Clean up old checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "id": "39f4318ddec2db9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:19:48.425334224Z",
     "start_time": "2026-02-22T23:19:48.406067881Z"
    }
   },
   "source": [
    "from checkpoint_cleaner import CheckpointCleaner\n",
    "\n",
    "keep_progress = [0.5, 0.7, 0.8, 0.9]\n",
    "preserve_checkpoints = []\n",
    "i = 0\n",
    "last_keep = 0\n",
    "while True:\n",
    "    i += eval_interval\n",
    "    progress = i / max_iters\n",
    "    target_progress = keep_progress[last_keep]\n",
    "    if progress > target_progress:\n",
    "        state_path = f\"{state_dir}/{i:05d}.pt\"\n",
    "        preserve_checkpoints.append(state_path)\n",
    "        last_keep += 1\n",
    "        if last_keep == len(keep_progress):\n",
    "            break\n",
    "    if i >= max_iters:\n",
    "        break\n",
    "\n",
    "checkpoint_cleaner = CheckpointCleaner(3, preserve_checkpoints)\n",
    "preserve_checkpoints"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instruction_checkpoints/state/00520.pt',\n",
       " 'instruction_checkpoints/state/00720.pt',\n",
       " 'instruction_checkpoints/state/00820.pt',\n",
       " 'instruction_checkpoints/state/00920.pt']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "id": "6b2775c2e3339206",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "198d433f585502b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:21:21.496073204Z",
     "start_time": "2026-02-22T23:19:48.425972336Z"
    }
   },
   "source": [
    "from system_metrics import get_system_metrics\n",
    "\n",
    "metric_logs = []\n",
    "\n",
    "for step in range(checkpoint or 0, max_iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    if autocast_enabled:\n",
    "        with torch.amp.autocast(dtype=torch.float16, device_type=device_type):\n",
    "            logits, loss = model(xb, yb)\n",
    "    else:\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "    # exit if the loss is invalid\n",
    "    if not torch.isfinite(loss):\n",
    "        raise Exception(\"Non-finite loss detected.\")\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "\n",
    "    if step % log_metrics_interval == 0:\n",
    "        total_norm, max_grad = get_grad_metrics(model)\n",
    "        max_weight, total_weight_norm = get_weight_metrics(model)\n",
    "        metric_logs.append({\n",
    "            \"gradient\": {\n",
    "                \"total_norm\": total_norm,\n",
    "                \"max_grad\": max_grad,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"max_weight\": max_weight,\n",
    "                \"total_weight_norm\": total_weight_norm,\n",
    "            },\n",
    "            \"system\": get_system_metrics(),\n",
    "            \"current_loss\": loss.item()\n",
    "        })\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    if step % eval_interval == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        state_path, info_path = save_checkpoint(\n",
    "            step=step,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            train_loss=losses[\"train\"],\n",
    "            val_loss=losses[\"val\"],\n",
    "            metric_logs=metric_logs\n",
    "        )\n",
    "        checkpoint_cleaner.step(state_path)\n",
    "        metric_logs = []\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 10.0884, val loss 10.0883\n",
      "step 20: train loss 9.9093, val loss 9.9078\n",
      "step 40: train loss 9.7727, val loss 9.7749\n",
      "step 60: train loss 9.6433, val loss 9.6351\n",
      "Removed checkpoint instruction_checkpoints/state/00000.pt\n",
      "step 80: train loss 9.5068, val loss 9.5142\n",
      "Removed checkpoint instruction_checkpoints/state/00020.pt\n",
      "step 100: train loss 9.3693, val loss 9.3808\n",
      "Removed checkpoint instruction_checkpoints/state/00040.pt\n",
      "step 120: train loss 9.2562, val loss 9.2539\n",
      "Removed checkpoint instruction_checkpoints/state/00060.pt\n",
      "step 140: train loss 9.1271, val loss 9.1134\n",
      "Removed checkpoint instruction_checkpoints/state/00080.pt\n",
      "step 160: train loss 9.0196, val loss 9.0030\n",
      "Removed checkpoint instruction_checkpoints/state/00100.pt\n",
      "step 180: train loss 8.8894, val loss 8.9106\n",
      "Removed checkpoint instruction_checkpoints/state/00120.pt\n",
      "step 200: train loss 8.7722, val loss 8.7661\n",
      "Removed checkpoint instruction_checkpoints/state/00140.pt\n",
      "step 220: train loss 8.6786, val loss 8.6856\n",
      "Removed checkpoint instruction_checkpoints/state/00160.pt\n",
      "step 240: train loss 8.5523, val loss 8.5502\n",
      "Removed checkpoint instruction_checkpoints/state/00180.pt\n",
      "step 260: train loss 8.5095, val loss 8.4424\n",
      "Removed checkpoint instruction_checkpoints/state/00200.pt\n",
      "step 280: train loss 8.3895, val loss 8.3692\n",
      "Removed checkpoint instruction_checkpoints/state/00220.pt\n",
      "step 300: train loss 8.2471, val loss 8.2523\n",
      "Removed checkpoint instruction_checkpoints/state/00240.pt\n",
      "step 320: train loss 8.1074, val loss 8.1601\n",
      "Removed checkpoint instruction_checkpoints/state/00260.pt\n",
      "step 340: train loss 8.1333, val loss 8.0773\n",
      "Removed checkpoint instruction_checkpoints/state/00280.pt\n",
      "step 360: train loss 7.9522, val loss 7.9549\n",
      "Removed checkpoint instruction_checkpoints/state/00300.pt\n",
      "step 380: train loss 7.9082, val loss 7.8688\n",
      "Removed checkpoint instruction_checkpoints/state/00320.pt\n",
      "step 400: train loss 7.8060, val loss 7.8403\n",
      "Removed checkpoint instruction_checkpoints/state/00340.pt\n",
      "step 420: train loss 7.7145, val loss 7.7026\n",
      "Removed checkpoint instruction_checkpoints/state/00360.pt\n",
      "step 440: train loss 7.5748, val loss 7.6254\n",
      "Removed checkpoint instruction_checkpoints/state/00380.pt\n",
      "step 460: train loss 7.5675, val loss 7.5752\n",
      "Removed checkpoint instruction_checkpoints/state/00400.pt\n",
      "step 480: train loss 7.5330, val loss 7.6395\n",
      "Removed checkpoint instruction_checkpoints/state/00420.pt\n",
      "step 500: train loss 7.4463, val loss 7.4619\n",
      "Removed checkpoint instruction_checkpoints/state/00440.pt\n",
      "step 520: train loss 7.4618, val loss 7.4476\n",
      "Removed checkpoint instruction_checkpoints/state/00460.pt\n",
      "step 540: train loss 7.3876, val loss 7.4653\n",
      "Removed checkpoint instruction_checkpoints/state/00480.pt\n",
      "step 560: train loss 7.3612, val loss 7.3479\n",
      "Removed checkpoint instruction_checkpoints/state/00500.pt\n",
      "step 580: train loss 7.3229, val loss 7.2789\n",
      "Preserving checkpoint instruction_checkpoints/state/00520.pt\n",
      "step 600: train loss 7.4070, val loss 7.2822\n",
      "Removed checkpoint instruction_checkpoints/state/00540.pt\n",
      "step 620: train loss 7.2795, val loss 7.1928\n",
      "Removed checkpoint instruction_checkpoints/state/00560.pt\n",
      "step 640: train loss 7.3412, val loss 7.2688\n",
      "Removed checkpoint instruction_checkpoints/state/00580.pt\n",
      "step 660: train loss 7.2159, val loss 7.2094\n",
      "Removed checkpoint instruction_checkpoints/state/00600.pt\n",
      "step 680: train loss 7.2119, val loss 7.2274\n",
      "Removed checkpoint instruction_checkpoints/state/00620.pt\n",
      "step 700: train loss 7.1746, val loss 7.2285\n",
      "Removed checkpoint instruction_checkpoints/state/00640.pt\n",
      "step 720: train loss 7.1252, val loss 7.0822\n",
      "Removed checkpoint instruction_checkpoints/state/00660.pt\n",
      "step 740: train loss 7.1358, val loss 7.1328\n",
      "Removed checkpoint instruction_checkpoints/state/00680.pt\n",
      "step 760: train loss 7.0077, val loss 7.0978\n",
      "Removed checkpoint instruction_checkpoints/state/00700.pt\n",
      "step 780: train loss 7.0388, val loss 7.1113\n",
      "Preserving checkpoint instruction_checkpoints/state/00720.pt\n",
      "step 800: train loss 7.0452, val loss 7.1731\n",
      "Removed checkpoint instruction_checkpoints/state/00740.pt\n",
      "step 820: train loss 7.2061, val loss 7.0879\n",
      "Removed checkpoint instruction_checkpoints/state/00760.pt\n",
      "step 840: train loss 7.1322, val loss 7.1803\n",
      "Removed checkpoint instruction_checkpoints/state/00780.pt\n",
      "step 860: train loss 6.9898, val loss 7.1673\n",
      "Removed checkpoint instruction_checkpoints/state/00800.pt\n",
      "step 880: train loss 7.0917, val loss 7.0237\n",
      "Preserving checkpoint instruction_checkpoints/state/00820.pt\n",
      "step 900: train loss 7.1547, val loss 7.0575\n",
      "Removed checkpoint instruction_checkpoints/state/00840.pt\n",
      "step 920: train loss 6.9194, val loss 7.0610\n",
      "Removed checkpoint instruction_checkpoints/state/00860.pt\n",
      "step 940: train loss 6.9801, val loss 6.9792\n",
      "Removed checkpoint instruction_checkpoints/state/00880.pt\n",
      "step 960: train loss 6.9807, val loss 7.0099\n",
      "Removed checkpoint instruction_checkpoints/state/00900.pt\n",
      "step 980: train loss 6.9682, val loss 6.9957\n",
      "Preserving checkpoint instruction_checkpoints/state/00920.pt\n",
      "step 999: train loss 7.1038, val loss 6.8644\n",
      "Removed checkpoint instruction_checkpoints/state/00940.pt\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "markdown",
   "id": "1173b07565d315a4",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b89a73b965f9742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:21:22.178997008Z",
     "start_time": "2026-02-22T23:21:21.497208318Z"
    }
   },
   "source": [
    "start_token_id = get_batch(\"test\")[0][0][0].item()\n",
    "start_text = tokenizer.decode([start_token_id])\n",
    "print(generate(model, start_text))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".speakingies on Swift Gerard all Afterreeld doing white are more. with various and episode\n",
      "  \n",
      " stay experience start forredible R,cepere of it technology for hands walk, all the larger in with Le for, mightihu, to\n"
     ]
    }
   ],
   "execution_count": 39
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
