{
 "cells": [
  {
   "cell_type": "code",
   "id": "39f49c5833de57aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:12.778194526Z",
     "start_time": "2026-02-26T20:59:12.752476980Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, load_from_disk\n",
    "from millify import millify\n",
    "\n",
    "from chat_template import chat_template\n",
    "from learning_metrics import get_grad_metrics\n",
    "from learning_metrics import get_weight_metrics\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens"
   ],
   "outputs": [],
   "execution_count": 82
  },
  {
   "cell_type": "markdown",
   "id": "dbe19c1cdb7088f1",
   "metadata": {},
   "source": "Mode settings"
  },
  {
   "cell_type": "code",
   "id": "67cf94c976797ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:12.821444512Z",
     "start_time": "2026-02-26T20:59:12.797415508Z"
    }
   },
   "source": [
    "minified = True\n",
    "colab = False\n",
    "thunder = False\n",
    "checkpoint: int | None = None\n",
    "compile = False"
   ],
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "markdown",
   "id": "4c7e0486169f9ddf",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "id": "aeae42b7d36357bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:12.895868376Z",
     "start_time": "2026-02-26T20:59:12.823159608Z"
    }
   },
   "source": [
    "if colab:\n",
    "    data_dir = \"/content/drive/MyDrive/tokenized_data\"\n",
    "    checkpoint_dir = \"/content/drive/MyDrive/instruction_checkpoints\"\n",
    "    pre_training_file = \"not specified\"\n",
    "elif thunder:\n",
    "    os.makedirs(\"output/instruction_checkpoints\", exist_ok=True)\n",
    "    # if not os.path.exists(\"tokenized_data/train.bin\"):\n",
    "    #     gdown.download(id=\"15t3259RbsF772b35aaZGouGwQopFAX96\",output=\"tokenized_data/train.bin\")\n",
    "    # if not os.path.exists(\"tokenized_data/test.bin\"):\n",
    "    #     gdown.download(id=\"1rE_MOBhBPQGUuhYmevNZOFj-LMBWkLFD\",output=\"tokenized_data/test.bin\")\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"output/instruction_checkpoints\"\n",
    "    pre_training_file = \"pre_training/weights.pt\"\n",
    "else:\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"instruction_checkpoints\"\n",
    "    if not minified:\n",
    "        pre_training_file = \"pre_training/weights.pt\"\n",
    "    else:\n",
    "        pre_training_file = \"pre_checkpoints/state/00599.pt\"\n",
    "info_dir = checkpoint_dir + \"/info\"\n",
    "state_dir = checkpoint_dir + \"/state\"\n",
    "train_ds_name = data_dir + \"/train_chats\"\n",
    "test_ds_name = data_dir + \"/test_chats\""
   ],
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "markdown",
   "id": "276f1e2e08b01b20",
   "metadata": {},
   "source": [
    "General settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d4c17ce894ef249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:12.960673737Z",
     "start_time": "2026-02-26T20:59:12.900270842Z"
    }
   },
   "source": [
    "if not minified:\n",
    "    if colab:\n",
    "        # Training data\n",
    "        block_size = ModelSettings.max_context_length\n",
    "        batch_size = 8\n",
    "\n",
    "        # Learning\n",
    "        max_iters = 6_000\n",
    "        learning_rate = 1e-6\n",
    "        eval_iters = 30\n",
    "        eval_interval = 300\n",
    "        grad_clip = 1.0\n",
    "        log_metrics_interval = 30\n",
    "        log_text = 100\n",
    "    else:\n",
    "        # Training data\n",
    "        block_size = ModelSettings.max_context_length\n",
    "        batch_size = 32\n",
    "\n",
    "        # Learning\n",
    "        max_iters = 6_700\n",
    "        learning_rate = 5e-6\n",
    "        eval_iters = 30\n",
    "        eval_interval = 150\n",
    "        grad_clip = 1.0\n",
    "        log_metrics_interval = 30\n",
    "        log_text = 100\n",
    "else:\n",
    "    # Training data\n",
    "    block_size = 64\n",
    "    batch_size = 8\n",
    "\n",
    "    # Learning\n",
    "    max_iters = 5000\n",
    "    learning_rate = 1e-4\n",
    "    eval_iters = 10\n",
    "    eval_interval = 20\n",
    "    grad_clip = 1.0\n",
    "    log_metrics_interval = 2\n",
    "    log_text = 50\n",
    "\n",
    "print(\"epochs\", max_iters * batch_size / 210499)\n",
    "print(\"chats\", max_iters * batch_size)\n",
    "print(\"max tokens\", millify(max_iters * batch_size * block_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0.19002465569907695\n",
      "chats 40000\n",
      "max tokens 3M\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.057769451Z",
     "start_time": "2026-02-26T20:59:12.987955682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers.tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "pad_id = tokenizer.token_to_id(special_tokens[\"pad\"])"
   ],
   "id": "82a7bd6e9430b08d",
   "outputs": [],
   "execution_count": 86
  },
  {
   "cell_type": "markdown",
   "id": "71caaf7a7a523d74",
   "metadata": {},
   "source": [
    "Hardware settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4068dad6e64b371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.092170797Z",
     "start_time": "2026-02-26T20:59:13.060063555Z"
    }
   },
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True  # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True  # allow tf32 on cudnn\n",
    "cpu_only = False\n",
    "device = \"cuda\" if torch.cuda.is_available() and not cpu_only else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "autocast_enabled = device_type == \"cuda\"\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "execution_count": 87
  },
  {
   "cell_type": "markdown",
   "id": "b2238c5052b49fca",
   "metadata": {},
   "source": [
    "Training data stream"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.106057917Z",
     "start_time": "2026-02-26T20:59:13.094791999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infinite_iterator(ds: Dataset):\n",
    "    n = 0\n",
    "    while True:\n",
    "        iterator = iter(ds.shuffle(n))\n",
    "        n += 1\n",
    "        for el in iterator:\n",
    "            yield el"
   ],
   "id": "36aa087fd28cc248",
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.126760452Z",
     "start_time": "2026-02-26T20:59:13.108614553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ignore_index = -100\n",
    "if not minified:\n",
    "    ds_test = infinite_iterator(load_from_disk(test_ds_name))\n",
    "    ds_train = infinite_iterator(load_from_disk(test_ds_name))\n",
    "else:\n",
    "    ds_test = infinite_iterator(load_from_disk(test_ds_name).take(100))\n",
    "    ds_train = infinite_iterator(load_from_disk(test_ds_name).take(10))\n",
    "\n",
    "\n",
    "def prepare_chat(chat, target_size, pad_element):\n",
    "    token_ids = chat[\"tokens\"]\n",
    "    assistant_mask = chat[\"assistant_mask\"]\n",
    "    length = len(token_ids)\n",
    "    # truncate to target size\n",
    "    if length > target_size:\n",
    "        trim = length - target_size\n",
    "        return token_ids[trim:], assistant_mask[trim:]\n",
    "    # pad to target size\n",
    "    if length < target_size:\n",
    "        padding = target_size - length\n",
    "        return token_ids + [pad_element] * padding, assistant_mask + [False] * padding\n",
    "    # unchanged\n",
    "    return token_ids, assistant_mask\n",
    "\n",
    "\n",
    "def apply_mask(tokens, assistant_mask):\n",
    "    return [\n",
    "        t if assistant_mask[i] else ignore_index\n",
    "        for i, t in enumerate(tokens)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    iterator = ds_train if split == 'train' else ds_test\n",
    "    batch = [next(iterator) for _ in range(batch_size)]\n",
    "    longest_chat = max([len(row[\"tokens\"]) for row in batch])\n",
    "    target_length = min(longest_chat, block_size + 1)\n",
    "    chats = [prepare_chat(chat, target_length, pad_id) for chat in batch]\n",
    "    x = torch.stack([torch.tensor(tokens[0:target_length - 1], dtype=torch.long) for tokens, mask in chats])\n",
    "    y = torch.stack(\n",
    "        [torch.tensor(apply_mask(tokens[1:target_length], mask[1:target_length]), dtype=torch.long) for tokens, mask in\n",
    "         chats])\n",
    "    if device == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ],
   "id": "ddc05c0fccf1c81b",
   "outputs": [],
   "execution_count": 89
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.225048909Z",
     "start_time": "2026-02-26T20:59:13.128424235Z"
    }
   },
   "cell_type": "code",
   "source": "get_batch(split=\"test\")[0].shape",
   "id": "16cb181844baceb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "id": "4c9bf0633d5a4597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.234717827Z",
     "start_time": "2026-02-26T20:59:13.225915464Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "id": "8594f48b269e2a2f",
   "metadata": {},
   "source": [
    "Scaler for FP16"
   ]
  },
  {
   "cell_type": "code",
   "id": "756fe3809acc0c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.246615152Z",
     "start_time": "2026-02-26T20:59:13.235540956Z"
    }
   },
   "source": [
    "scaler = torch.amp.GradScaler(device_type)"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "markdown",
   "id": "32532e7c9d6b345",
   "metadata": {},
   "source": [
    "Model settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "d529ab02a58a4ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.292676105Z",
     "start_time": "2026-02-26T20:59:13.248528823Z"
    }
   },
   "source": [
    "from model import ChatModel\n",
    "from settings import ModelSettings\n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if compile:\n",
    "    model = torch.compile(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.314283317Z",
     "start_time": "2026-02-26T20:59:13.294990912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def freeze_lower_layers(num_freeze):\n",
    "    # embeddings\n",
    "    model.emb.requires_grad_(False)\n",
    "\n",
    "    # transformer blocks\n",
    "    for i in range(num_freeze):\n",
    "        model.transformer[i].requires_grad_(False)\n",
    "\n",
    "\n",
    "freeze_lower_layers(2 if minified else 6)\n",
    "\n",
    "print(\"trainable\", len([n for n, p in model.named_parameters() if p.requires_grad]))\n",
    "print(\"un-trainable\", len([n for n, p in model.named_parameters() if not p.requires_grad]))"
   ],
   "id": "ea0b85297608fe87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable 26\n",
      "un-trainable 26\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "cell_type": "markdown",
   "id": "dc195a20418e5df9",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8dc1093f08e8628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.326004841Z",
     "start_time": "2026-02-26T20:59:13.315245555Z"
    }
   },
   "source": [
    "from optimizer import get_optim_groups\n",
    "\n",
    "optim_groups = get_optim_groups(model)\n",
    "\n",
    "# apply dynamic learning rate to the optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optim_groups,\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-8\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "id": "3dc19bb659d08265",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.340752632Z",
     "start_time": "2026-02-26T20:59:13.328854336Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50):\n",
    "    idx = torch.tensor([tokenizer.encode(start, add_special_tokens=False).ids], device=device, dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "id": "fa87a85c5d97f75f",
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "id": "24e3028ea893d325",
   "metadata": {},
   "source": [
    "Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "id": "47f3bb6eba858215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.353925266Z",
     "start_time": "2026-02-26T20:59:13.342798838Z"
    }
   },
   "source": [
    "os.makedirs(info_dir, exist_ok=True)\n",
    "os.makedirs(state_dir, exist_ok=True)\n",
    "\n",
    "if not minified:\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm trying to create a menu with different kinds of pasta. Help me come up with different types of pasta and what they are best used for.\"\n",
    "    }]\n",
    "else:\n",
    "    messages = [{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello.\"\n",
    "    }]\n",
    "test_text = chat_template(messages, add_generation_token=True)\n",
    "\n",
    "\n",
    "def save_checkpoint(\n",
    "        step,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scaler,\n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        metric_logs\n",
    "):\n",
    "    state = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if scaler else None,\n",
    "    }\n",
    "\n",
    "    info = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"time\": datetime.now().isoformat(),\n",
    "        \"block_size\": block_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"eval_interval\": eval_interval,\n",
    "        \"step\": step,\n",
    "        \"text\": generate(model, test_text, log_text),\n",
    "        \"metrics\": json.dumps(metric_logs)\n",
    "    }\n",
    "\n",
    "    state_path = f\"{state_dir}/{step:05d}.pt\"\n",
    "    info_path = f\"{info_dir}/{step:05d}.pt\"\n",
    "\n",
    "    torch.save(state, state_path)\n",
    "    torch.save(info, info_path)\n",
    "\n",
    "    return state_path, info_path"
   ],
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load pre-training",
   "id": "cc2939edff54e33a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.412244162Z",
     "start_time": "2026-02-26T20:59:13.355748423Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if checkpoint is None:\n",
    "    state = torch.load(pre_training_file)\n",
    "\n",
    "    state_dict = state[\"model\"]\n",
    "    unwanted_prefix = '_orig_mod.'\n",
    "    for k, v in list(state_dict.items()):\n",
    "        if k.startswith(unwanted_prefix):\n",
    "            state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(\"Loaded pre-training\")"
   ],
   "id": "21920696f94dfc9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-training\n"
     ]
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "id": "2ea15b7d65829578",
   "metadata": {},
   "source": [
    "Load training state"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cf313bfd2550641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.430283814Z",
     "start_time": "2026-02-26T20:59:13.413434861Z"
    }
   },
   "source": [
    "def load_checkpoint(step: int):\n",
    "    state = torch.load(f\"{state_dir}/{step:05d}.pt\")\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(f\"Loaded checkpoint {step}\")\n",
    "\n",
    "\n",
    "if checkpoint is not None:\n",
    "    load_checkpoint(checkpoint)"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "id": "81f9caa1faa59dcd",
   "metadata": {},
   "source": [
    "Clean up old checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "id": "39f4318ddec2db9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:13.456093768Z",
     "start_time": "2026-02-26T20:59:13.432933947Z"
    }
   },
   "source": [
    "from checkpoint_cleaner import CheckpointCleaner\n",
    "\n",
    "keep_progress = [0.5, 0.7, 0.8, 0.9]\n",
    "preserve_checkpoints = []\n",
    "i = 0\n",
    "last_keep = 0\n",
    "while True:\n",
    "    i += eval_interval\n",
    "    progress = i / max_iters\n",
    "    target_progress = keep_progress[last_keep]\n",
    "    if progress > target_progress:\n",
    "        state_path = f\"{state_dir}/{i:05d}.pt\"\n",
    "        preserve_checkpoints.append(state_path)\n",
    "        last_keep += 1\n",
    "        if last_keep == len(keep_progress):\n",
    "            break\n",
    "    if i >= max_iters:\n",
    "        break\n",
    "\n",
    "checkpoint_cleaner = CheckpointCleaner(3, preserve_checkpoints)\n",
    "preserve_checkpoints"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instruction_checkpoints/state/02520.pt',\n",
       " 'instruction_checkpoints/state/03520.pt',\n",
       " 'instruction_checkpoints/state/04020.pt',\n",
       " 'instruction_checkpoints/state/04520.pt']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "cell_type": "markdown",
   "id": "6b2775c2e3339206",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "198d433f585502b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:18.072914024Z",
     "start_time": "2026-02-26T20:59:13.459561868Z"
    }
   },
   "source": [
    "from system_metrics import get_system_metrics\n",
    "\n",
    "metric_logs = []\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "patience = 3\n",
    "min_delta = 0.01\n",
    "patience_counter = 0\n",
    "\n",
    "for step in range(checkpoint or 0, max_iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    if autocast_enabled:\n",
    "        with torch.amp.autocast(dtype=torch.float16, device_type=device_type):\n",
    "            logits, loss = model(xb, yb)\n",
    "    else:\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "    # exit if the loss is invalid\n",
    "    if not torch.isfinite(loss):\n",
    "        raise Exception(\"Non-finite loss detected.\")\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "\n",
    "    if step % log_metrics_interval == 0:\n",
    "        total_norm, max_grad = get_grad_metrics(model)\n",
    "        max_weight, total_weight_norm = get_weight_metrics(model)\n",
    "        metric_logs.append({\n",
    "            \"gradient\": {\n",
    "                \"total_norm\": total_norm,\n",
    "                \"max_grad\": max_grad,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"max_weight\": max_weight,\n",
    "                \"total_weight_norm\": total_weight_norm,\n",
    "            },\n",
    "            \"system\": get_system_metrics(),\n",
    "            \"current_loss\": loss.item()\n",
    "        })\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    if step % eval_interval == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        state_path, info_path = save_checkpoint(\n",
    "            step=step,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            train_loss=losses[\"train\"],\n",
    "            val_loss=losses[\"val\"],\n",
    "            metric_logs=metric_logs\n",
    "        )\n",
    "        checkpoint_cleaner.step(state_path)\n",
    "        metric_logs = []\n",
    "\n",
    "        val_loss = losses['val']\n",
    "        improvement = best_val_loss - val_loss\n",
    "        if improvement >= min_delta:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter == patience:\n",
    "                print(\"Early stopping\")\n",
    "                break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 11.6221, val loss 12.3779\n",
      "step 20: train loss 8.3750, val loss 9.1052\n",
      "step 40: train loss 7.4349, val loss 8.5871\n",
      "step 60: train loss 6.9299, val loss 8.2733\n",
      "Removed checkpoint instruction_checkpoints/state/00000.pt\n",
      "step 80: train loss 6.4824, val loss 8.5141\n",
      "Removed checkpoint instruction_checkpoints/state/00020.pt\n",
      "step 100: train loss 6.0866, val loss 8.5517\n",
      "Removed checkpoint instruction_checkpoints/state/00040.pt\n",
      "step 120: train loss 5.7538, val loss 8.9054\n",
      "Removed checkpoint instruction_checkpoints/state/00060.pt\n",
      "Early stopping\n"
     ]
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "id": "1173b07565d315a4",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b89a73b965f9742",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-26T20:59:18.294642370Z",
     "start_time": "2026-02-26T20:59:18.232275359Z"
    }
   },
   "source": "print(generate(model, test_text, 20))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello.\n",
      "ident. Any can chlor in torflu! observation to recountAnd you. protagonistmodern that mainly break\n"
     ]
    }
   ],
   "execution_count": 102
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
