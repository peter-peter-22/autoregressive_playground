{
 "cells": [
  {
   "cell_type": "code",
   "id": "39f49c5833de57aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:41:15.799905563Z",
     "start_time": "2026-02-25T21:41:13.748278628Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import Dataset, load_from_disk\n",
    "from millify import millify\n",
    "\n",
    "from chat_template import chat_template\n",
    "from learning_metrics import get_grad_metrics\n",
    "from learning_metrics import get_weight_metrics\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "dbe19c1cdb7088f1",
   "metadata": {},
   "source": [
    "Mode settings\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "67cf94c976797ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:42:00.429550101Z",
     "start_time": "2026-02-25T21:42:00.419566595Z"
    }
   },
   "source": [
    "minified = False\n",
    "colab = False\n",
    "thunder = True\n",
    "checkpoint: int | None = None\n",
    "compile = True"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "4c7e0486169f9ddf",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "id": "aeae42b7d36357bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.506800625Z",
     "start_time": "2026-02-25T21:38:04.489630751Z"
    }
   },
   "source": [
    "if colab:\n",
    "    data_dir = \"/content/drive/MyDrive/tokenized_data\"\n",
    "    checkpoint_dir = \"/content/drive/MyDrive/instruction_checkpoints\"\n",
    "elif thunder:\n",
    "    os.makedirs(\"output/instruction_checkpoints\", exist_ok=True)\n",
    "    # if not os.path.exists(\"tokenized_data/train.bin\"):\n",
    "    #     gdown.download(id=\"15t3259RbsF772b35aaZGouGwQopFAX96\",output=\"tokenized_data/train.bin\")\n",
    "    # if not os.path.exists(\"tokenized_data/test.bin\"):\n",
    "    #     gdown.download(id=\"1rE_MOBhBPQGUuhYmevNZOFj-LMBWkLFD\",output=\"tokenized_data/test.bin\")\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"output/instruction_checkpoints\"\n",
    "    pre_training_file = \"pre_training/weights.pt\"\n",
    "else:\n",
    "    data_dir = \"tokenized_data\"\n",
    "    checkpoint_dir = \"instruction_checkpoints\"\n",
    "    if not minified:\n",
    "        pre_training_file = \"pre_training/weights.pt\"\n",
    "    else:\n",
    "        pre_training_file = \"pre_checkpoints/state/00599.pt\"\n",
    "info_dir = checkpoint_dir + \"/info\"\n",
    "state_dir = checkpoint_dir + \"/state\"\n",
    "train_ds_name = data_dir + \"/train_chats\"\n",
    "test_ds_name = data_dir + \"/test_chats\""
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "id": "276f1e2e08b01b20",
   "metadata": {},
   "source": [
    "General settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "4d4c17ce894ef249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:46:53.377103630Z",
     "start_time": "2026-02-25T21:46:53.348891831Z"
    }
   },
   "source": [
    "if not minified:\n",
    "    if colab:\n",
    "        # Training data\n",
    "        block_size = ModelSettings.max_context_length\n",
    "        batch_size = 8\n",
    "\n",
    "        # Learning\n",
    "        max_iters = 6_000\n",
    "        learning_rate = 1e-6\n",
    "        eval_iters = 30\n",
    "        eval_interval = 300\n",
    "        grad_clip = 1.0\n",
    "        log_metrics_interval = 30\n",
    "        log_text = 100\n",
    "    else:\n",
    "        # Training data\n",
    "        block_size = ModelSettings.max_context_length\n",
    "        batch_size = 32\n",
    "\n",
    "        # Learning\n",
    "        max_iters = 6_700\n",
    "        learning_rate = 5e-6\n",
    "        eval_iters = 30\n",
    "        eval_interval = 150\n",
    "        grad_clip = 1.0\n",
    "        log_metrics_interval = 30\n",
    "        log_text = 100\n",
    "else:\n",
    "    # Training data\n",
    "    block_size = 64\n",
    "    batch_size = 8\n",
    "\n",
    "    # Learning\n",
    "    max_iters = 500\n",
    "    learning_rate = 1e-4\n",
    "    eval_iters = 10\n",
    "    eval_interval = 20\n",
    "    grad_clip = 1.0\n",
    "    log_metrics_interval = 2\n",
    "    log_text = 50\n",
    "\n",
    "print(\"epochs\", max_iters * batch_size / 210499)\n",
    "print(\"chats\", max_iters * batch_size)\n",
    "print(\"max tokens\", millify(max_iters * batch_size * block_size))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1.0185321545470525\n",
      "chats 214400\n",
      "max tokens 214M\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.620213985Z",
     "start_time": "2026-02-25T21:38:04.567488028Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tokenizers.tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "pad_id = tokenizer.token_to_id(special_tokens[\"pad\"])"
   ],
   "id": "82a7bd6e9430b08d",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "71caaf7a7a523d74",
   "metadata": {},
   "source": [
    "Hardware settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "b4068dad6e64b371",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.643076874Z",
     "start_time": "2026-02-25T21:38:04.622467933Z"
    }
   },
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True  # allow tf32 on matmul\n",
    "torch.backends.cudnn.allow_tf32 = True  # allow tf32 on cudnn\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device_type = 'cuda' if 'cuda' in device else 'cpu'\n",
    "autocast_enabled = device_type == \"cuda\"\n",
    "print(device)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "b2238c5052b49fca",
   "metadata": {},
   "source": [
    "Training data stream"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.650704332Z",
     "start_time": "2026-02-25T21:38:04.643953974Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def infinite_iterator(ds: Dataset):\n",
    "    n = 0\n",
    "    while True:\n",
    "        iterator = iter(ds.shuffle(n))\n",
    "        n += 1\n",
    "        for el in iterator:\n",
    "            yield el"
   ],
   "id": "36aa087fd28cc248",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.673081846Z",
     "start_time": "2026-02-25T21:38:04.651486256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ignore_index = -100\n",
    "if not minified:\n",
    "    ds_test = infinite_iterator(load_from_disk(test_ds_name))\n",
    "    ds_train = infinite_iterator(load_from_disk(test_ds_name))\n",
    "else:\n",
    "    ds_test = infinite_iterator(load_from_disk(test_ds_name).take(100))\n",
    "    ds_train = infinite_iterator(load_from_disk(test_ds_name).take(10))\n",
    "\n",
    "\n",
    "def prepare_chat(chat, target_size, pad_element):\n",
    "    token_ids = chat[\"tokens\"]\n",
    "    assistant_mask = chat[\"assistant_mask\"]\n",
    "    length = len(token_ids)\n",
    "    # truncate to target size\n",
    "    if length > target_size:\n",
    "        trim = length - target_size\n",
    "        return token_ids[trim:], assistant_mask[trim:]\n",
    "    # pad to target size\n",
    "    if length < target_size:\n",
    "        padding = target_size - length\n",
    "        return token_ids + [pad_element] * padding, assistant_mask + [False] * padding\n",
    "    # unchanged\n",
    "    return token_ids, assistant_mask\n",
    "\n",
    "\n",
    "def apply_mask(tokens, assistant_mask):\n",
    "    return [\n",
    "        t if assistant_mask[i] else ignore_index\n",
    "        for i, t in enumerate(tokens)\n",
    "    ]\n",
    "\n",
    "\n",
    "def get_batch(split):\n",
    "    iterator = ds_train if split == 'train' else ds_test\n",
    "    batch = [next(iterator) for _ in range(batch_size)]\n",
    "    longest_chat = max([len(row[\"tokens\"]) for row in batch])\n",
    "    target_length = min(longest_chat, block_size + 1)\n",
    "    chats = [prepare_chat(chat, target_length, pad_id) for chat in batch]\n",
    "    x = torch.stack([torch.tensor(tokens[0:target_length - 1], dtype=torch.long) for tokens, mask in chats])\n",
    "    y = torch.stack(\n",
    "        [torch.tensor(apply_mask(tokens[1:target_length], mask[1:target_length]), dtype=torch.long) for tokens, mask in\n",
    "         chats])\n",
    "    if device == 'cuda':\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y"
   ],
   "id": "ddc05c0fccf1c81b",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.696195070Z",
     "start_time": "2026-02-25T21:38:04.674981083Z"
    }
   },
   "cell_type": "code",
   "source": "get_batch(split=\"test\")[0].shape",
   "id": "16cb181844baceb5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 64])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "4c9bf0633d5a4597",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.704534290Z",
     "start_time": "2026-02-25T21:38:04.697057507Z"
    }
   },
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = get_batch(split)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "id": "8594f48b269e2a2f",
   "metadata": {},
   "source": [
    "Scaler for FP16"
   ]
  },
  {
   "cell_type": "code",
   "id": "756fe3809acc0c3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.718757582Z",
     "start_time": "2026-02-25T21:38:04.705984805Z"
    }
   },
   "source": [
    "scaler = torch.amp.GradScaler(device_type)"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "markdown",
   "id": "32532e7c9d6b345",
   "metadata": {},
   "source": [
    "Model settings"
   ]
  },
  {
   "cell_type": "code",
   "id": "d529ab02a58a4ac0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.765126813Z",
     "start_time": "2026-02-25T21:38:04.723910698Z"
    }
   },
   "source": [
    "from model import ChatModel\n",
    "from settings import ModelSettings\n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=block_size,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "if compile:\n",
    "    model = torch.compile(model)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.783927277Z",
     "start_time": "2026-02-25T21:38:04.766710434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def freeze_lower_layers(num_freeze):\n",
    "    # embeddings\n",
    "    model.emb.requires_grad_(False)\n",
    "\n",
    "    # transformer blocks\n",
    "    for i in range(num_freeze):\n",
    "        model.transformer[i].requires_grad_(False)\n",
    "\n",
    "\n",
    "freeze_lower_layers(2 if minified else 6)\n",
    "\n",
    "print(\"trainable\", len([n for n, p in model.named_parameters() if p.requires_grad]))\n",
    "print(\"un-trainable\", len([n for n, p in model.named_parameters() if not p.requires_grad]))"
   ],
   "id": "ea0b85297608fe87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable 26\n",
      "un-trainable 26\n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "id": "dc195a20418e5df9",
   "metadata": {},
   "source": [
    "Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "id": "f8dc1093f08e8628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.792383041Z",
     "start_time": "2026-02-25T21:38:04.784682606Z"
    }
   },
   "source": [
    "from optimizer import get_optim_groups\n",
    "\n",
    "optim_groups = get_optim_groups(model)\n",
    "\n",
    "# apply dynamic learning rate to the optimizer\n",
    "optimizer = torch.optim.AdamW(\n",
    "    optim_groups,\n",
    "    lr=learning_rate,\n",
    "    betas=(0.9, 0.95),\n",
    "    eps=1e-8\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "id": "3dc19bb659d08265",
   "metadata": {},
   "source": [
    "Generate"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.803956385Z",
     "start_time": "2026-02-25T21:38:04.793277415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50):\n",
    "    idx = torch.tensor([tokenizer.encode(start, add_special_tokens=False).ids], device=device, dtype=torch.long)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = nn.functional.softmax(logits, dim=-1)\n",
    "        next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "id": "fa87a85c5d97f75f",
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "markdown",
   "id": "24e3028ea893d325",
   "metadata": {},
   "source": [
    "Checkpointer"
   ]
  },
  {
   "cell_type": "code",
   "id": "47f3bb6eba858215",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:04.816754289Z",
     "start_time": "2026-02-25T21:38:04.805724318Z"
    }
   },
   "source": [
    "os.makedirs(info_dir, exist_ok=True)\n",
    "os.makedirs(state_dir, exist_ok=True)\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"I'm trying to create a menu with different kinds of pasta. Help me come up with different types of pasta and what they are best used for.\"\n",
    "}]\n",
    "test_text = chat_template(messages, add_generation_token=True)\n",
    "\n",
    "\n",
    "def save_checkpoint(\n",
    "        step,\n",
    "        model,\n",
    "        optimizer,\n",
    "        scaler,\n",
    "        train_loss,\n",
    "        val_loss,\n",
    "        metric_logs\n",
    "):\n",
    "    state = {\n",
    "        \"model\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "        \"scaler\": scaler.state_dict() if scaler else None,\n",
    "    }\n",
    "\n",
    "    info = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"time\": datetime.now().isoformat(),\n",
    "        \"block_size\": block_size,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"eval_interval\": eval_interval,\n",
    "        \"step\": step,\n",
    "        \"text\": generate(model, test_text, log_text),\n",
    "        \"metrics\": json.dumps(metric_logs)\n",
    "    }\n",
    "\n",
    "    state_path = f\"{state_dir}/{step:05d}.pt\"\n",
    "    info_path = f\"{info_dir}/{step:05d}.pt\"\n",
    "\n",
    "    torch.save(state, state_path)\n",
    "    torch.save(info, info_path)\n",
    "\n",
    "    return state_path, info_path"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load pre-training",
   "id": "cc2939edff54e33a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:22.437852487Z",
     "start_time": "2026-02-25T21:38:22.316388234Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if checkpoint is None:\n",
    "    state = torch.load(pre_training_file)\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(\"Loaded pre-training\")"
   ],
   "id": "21920696f94dfc9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pre-training\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "markdown",
   "id": "2ea15b7d65829578",
   "metadata": {},
   "source": [
    "Load training state"
   ]
  },
  {
   "cell_type": "code",
   "id": "1cf313bfd2550641",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:22.471118677Z",
     "start_time": "2026-02-25T21:38:22.451070572Z"
    }
   },
   "source": [
    "def load_checkpoint(step: int):\n",
    "    state = torch.load(f\"{state_dir}/{step:05d}.pt\")\n",
    "    model.load_state_dict(state[\"model\"])\n",
    "    optimizer.load_state_dict(state[\"optimizer\"])\n",
    "    scaler.load_state_dict(state[\"scaler\"])\n",
    "    print(f\"Loaded checkpoint {step}\")\n",
    "\n",
    "\n",
    "if checkpoint is not None:\n",
    "    load_checkpoint(checkpoint)"
   ],
   "outputs": [],
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "id": "81f9caa1faa59dcd",
   "metadata": {},
   "source": [
    "Clean up old checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "id": "39f4318ddec2db9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:38:22.497877469Z",
     "start_time": "2026-02-25T21:38:22.474501379Z"
    }
   },
   "source": [
    "from checkpoint_cleaner import CheckpointCleaner\n",
    "\n",
    "keep_progress = [0.5, 0.7, 0.8, 0.9]\n",
    "preserve_checkpoints = []\n",
    "i = 0\n",
    "last_keep = 0\n",
    "while True:\n",
    "    i += eval_interval\n",
    "    progress = i / max_iters\n",
    "    target_progress = keep_progress[last_keep]\n",
    "    if progress > target_progress:\n",
    "        state_path = f\"{state_dir}/{i:05d}.pt\"\n",
    "        preserve_checkpoints.append(state_path)\n",
    "        last_keep += 1\n",
    "        if last_keep == len(keep_progress):\n",
    "            break\n",
    "    if i >= max_iters:\n",
    "        break\n",
    "\n",
    "checkpoint_cleaner = CheckpointCleaner(3, preserve_checkpoints)\n",
    "preserve_checkpoints"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['instruction_checkpoints/state/00260.pt',\n",
       " 'instruction_checkpoints/state/00360.pt',\n",
       " 'instruction_checkpoints/state/00420.pt',\n",
       " 'instruction_checkpoints/state/00460.pt']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "cell_type": "markdown",
   "id": "6b2775c2e3339206",
   "metadata": {},
   "source": [
    "Training loop"
   ]
  },
  {
   "cell_type": "code",
   "id": "198d433f585502b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-25T21:39:07.924893417Z",
     "start_time": "2026-02-25T21:38:22.501398026Z"
    }
   },
   "source": [
    "from system_metrics import get_system_metrics\n",
    "\n",
    "metric_logs = []\n",
    "\n",
    "for step in range(checkpoint or 0, max_iters):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    xb, yb = get_batch(\"train\")\n",
    "\n",
    "    if autocast_enabled:\n",
    "        with torch.amp.autocast(dtype=torch.float16, device_type=device_type):\n",
    "            logits, loss = model(xb, yb)\n",
    "    else:\n",
    "        logits, loss = model(xb, yb)\n",
    "\n",
    "    # exit if the loss is invalid\n",
    "    if not torch.isfinite(loss):\n",
    "        raise Exception(\"Non-finite loss detected.\")\n",
    "\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.unscale_(optimizer)\n",
    "\n",
    "    if step % log_metrics_interval == 0:\n",
    "        total_norm, max_grad = get_grad_metrics(model)\n",
    "        max_weight, total_weight_norm = get_weight_metrics(model)\n",
    "        metric_logs.append({\n",
    "            \"gradient\": {\n",
    "                \"total_norm\": total_norm,\n",
    "                \"max_grad\": max_grad,\n",
    "            },\n",
    "            \"weight\": {\n",
    "                \"max_weight\": max_weight,\n",
    "                \"total_weight_norm\": total_weight_norm,\n",
    "            },\n",
    "            \"system\": get_system_metrics(),\n",
    "            \"current_loss\": loss.item()\n",
    "        })\n",
    "\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n",
    "\n",
    "    if step % eval_interval == 0 or step == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {step}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "        state_path, info_path = save_checkpoint(\n",
    "            step=step,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scaler=scaler,\n",
    "            train_loss=losses[\"train\"],\n",
    "            val_loss=losses[\"val\"],\n",
    "            metric_logs=metric_logs\n",
    "        )\n",
    "        checkpoint_cleaner.step(state_path)\n",
    "        metric_logs = []\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 11.6222, val loss 12.3779\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1173b07565d315a4",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "id": "3b89a73b965f9742",
   "metadata": {},
   "source": "print(generate(model, test_text, 20))",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
