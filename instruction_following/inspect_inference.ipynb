{
 "cells": [
  {
   "cell_type": "code",
   "id": "809914ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:19:27.243914195Z",
     "start_time": "2026-02-21T21:19:22.507196810Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import Tokenizer\n",
    "from settings import ModelSettings\n",
    "from model import ChatModel\n",
    "from special_tokens import special_tokens\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50, temperature=0.3, top_k=10, argmax=False, stop_tokens=None):\n",
    "    idx = torch.tensor(\n",
    "        [tokenizer.encode(start, add_special_tokens=False).ids],\n",
    "        device=device,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length :]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        top_logits, top_pos=torch.topk(logits,top_k)\n",
    "        logits=torch.where(\n",
    "            logits<top_logits[:,-1],\n",
    "            input=torch.tensor(float(\"-inf\")),\n",
    "            other=logits\n",
    "        )\n",
    "\n",
    "        probs = nn.functional.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "\n",
    "        if argmax:\n",
    "            next_id = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "        if stop_tokens and idx[0][-1].tolist() in stop_tokens:\n",
    "            print(\"Reached stop token\")\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4552ef70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:19:29.851957403Z",
     "start_time": "2026-02-21T21:19:27.325609673Z"
    }
   },
   "source": [
    "minified=False \n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=ModelSettings.max_context_length,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=64,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3d29b4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:19:31.288618899Z",
     "start_time": "2026-02-21T21:19:30.166743981Z"
    }
   },
   "source": [
    "step=100_000\n",
    "state = torch.load(f\"output_100k/pre_checkpoints/state/{step:05d}.pt\",map_location=torch.device('cpu'))"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "d06a9442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:19:33.255646718Z",
     "start_time": "2026-02-21T21:19:32.910703200Z"
    }
   },
   "source": [
    "state_dict=state[\"model\"]\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "3bb2db89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:19:33.718807241Z",
     "start_time": "2026-02-21T21:19:33.354586905Z"
    }
   },
   "source": [
    "model.load_state_dict(state[\"model\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "007fe508",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:20:03.129682253Z",
     "start_time": "2026-02-21T21:19:33.901872387Z"
    }
   },
   "source": [
    "print(generate(model, \"Hello\",200))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I'm so happy to see you!\"\n",
      "\n",
      "The little girl smiled and said, \"Thank you!\"\n",
      "\n",
      "The little girl was so excited that she ran off to tell her mom. She was so happy to be able to help the little girl.\n",
      "Once upon a time there was a little girl named Jane. She was three years old and loved to explore.\n",
      "\n",
      "One day, Jane was walking in the park when she saw a big tree. She wanted to climb it, but it was too high for her to reach.\n",
      "\n",
      "\"Mommy, can you help me?\" Jane asked.\n",
      "\n",
      "\"Yes, I can help you,\" said Mommy.\n",
      "\n",
      "Mommy climbed up the tree and Jane was so happy to be able to climb. She felt so proud of herself for being so brave.\n",
      "\n",
      "\"Thank you Mommy!\" Jane said.\n",
      "\n",
      "Mommy smiled and said, \"You're welcome, Jane. I'm glad I could help you.\"\n",
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "2b464fe3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:20:30.058165686Z",
     "start_time": "2026-02-21T21:20:04.161614828Z"
    }
   },
   "source": [
    "print(generate(model, \"Once upon a time\",200))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the garden. One day, she saw a big, scary shadow. It was so big that she couldn't see very well. \n",
      "\n",
      "Lily's mommy told her that it was just a shadows. But Lily didn't understand why it was so scary. She thought it was just a big, scary shadow. \n",
      "\n",
      "Later that day, Lily went to the store with her mommy. She saw a toy that she really wanted. She asked her mommy if she could buy it. Her mommy said yes and they bought it. \n",
      "\n",
      "Lily was so happy that she could buy the toy she wanted. She played with it all day and showed it to all her friends. They all thought it was so cool. From that day on, Lily never felt scared of big, scary shadow again.\n",
      "Once upon a time, there was a little girl named Lily. She loved to play outside in the sun and\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "c2fb924f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:20:31.275653535Z",
     "start_time": "2026-02-21T21:20:31.134354219Z"
    }
   },
   "source": [
    "stop_tokens= tokenizer.encode(special_tokens[\"end_of_turn\"]+ special_tokens[\"eos\"],add_special_tokens=False).ids\n",
    "print(stop_tokens)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "ad46900a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:20:52.121213452Z",
     "start_time": "2026-02-21T21:20:31.293144336Z"
    }
   },
   "source": [
    "print(\n",
    "    generate(\n",
    "        model,\n",
    "        special_tokens[\"bos\"]\n",
    "        +special_tokens[\"user\"]\n",
    "        + \"Can foxes fit down rabbit burrows?\"\n",
    "        + special_tokens[\"end_of_turn\"]\n",
    "        + \"\\n\"\n",
    "        + special_tokens[\"assistant\"],\n",
    "        200,\n",
    "        stop_tokens=stop_tokens\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can foxes fit down rabbit burrows?\n",
      "Foxes are a great way to get rid of the foxes. They can be very fast, but they can also be very difficult to catch. Some foxes have a lot of teeth and can be very fast, but they can also be very fast. Foxes are very fast and can be very fast. They can be very fast, but they can also be very fast. Foxes are very fast and can be very fast. They can be very fast, but they can also be very fast. Foxes are very fast and can be very fast. They can be very fast, but they can also be very fast. Foxes are very fast, but they can also be very fast. Foxes are very fast, but they can also be very fast. Foxes are very fast, but they can be very fast. Foxes are very fast, but they can be very fast. Foxes are very fast, but they can be very fast. Foxes are very fast\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "92d5c415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:20:53.700551746Z",
     "start_time": "2026-02-21T21:20:53.089592710Z"
    }
   },
   "source": [
    "print(\n",
    "    generate(\n",
    "        model,\n",
    "        special_tokens[\"bos\"]\n",
    "        +special_tokens[\"user\"]\n",
    "        + \"Hello\"\n",
    "        + special_tokens[\"end_of_turn\"]\n",
    "        + \"\\n\"\n",
    "        + special_tokens[\"assistant\"],\n",
    "        200,\n",
    "        stop_tokens=stop_tokens\n",
    "    )\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached stop token\n",
      "Hello\n",
      "Hello, I'm looking for a friend. What's your name?\"\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "da473160",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-21T21:20:58.914178624Z",
     "start_time": "2026-02-21T21:20:54.818175444Z"
    }
   },
   "source": [
    "from datasets import load_from_disk\n",
    "\n",
    "ds=load_from_disk(\"tokenized_data/robots_test\").take(5)\n",
    "for m in ds:\n",
    "    print(list(map(tokenizer.id_to_token,m[\"tokens\"])))"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/peter/PycharmProjects/autoregressive_playground/instruction_following/tokenized_data/robots_test/data-00000-of-00001.arrow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_from_disk\n\u001B[0;32m----> 3\u001B[0m ds\u001B[38;5;241m=\u001B[39m\u001B[43mload_from_disk\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mtokenized_data/robots_test\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mtake(\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m m \u001B[38;5;129;01min\u001B[39;00m ds:\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mmap\u001B[39m(tokenizer\u001B[38;5;241m.\u001B[39mid_to_token,m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtokens\u001B[39m\u001B[38;5;124m\"\u001B[39m])))\n",
      "File \u001B[0;32m~/PycharmProjects/autoregressive_playground/.venv/lib/python3.10/site-packages/datasets/load.py:2693\u001B[0m, in \u001B[0;36mload_from_disk\u001B[0;34m(dataset_path, fs, keep_in_memory, storage_options)\u001B[0m\n\u001B[1;32m   2689\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDirectory \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdataset_path\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   2690\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fs\u001B[38;5;241m.\u001B[39misfile(posixpath\u001B[38;5;241m.\u001B[39mjoin(dataset_path, config\u001B[38;5;241m.\u001B[39mDATASET_INFO_FILENAME)) \u001B[38;5;129;01mand\u001B[39;00m fs\u001B[38;5;241m.\u001B[39misfile(\n\u001B[1;32m   2691\u001B[0m     posixpath\u001B[38;5;241m.\u001B[39mjoin(dataset_path, config\u001B[38;5;241m.\u001B[39mDATASET_STATE_JSON_FILENAME)\n\u001B[1;32m   2692\u001B[0m ):\n\u001B[0;32m-> 2693\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_from_disk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep_in_memory\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mkeep_in_memory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2694\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m fs\u001B[38;5;241m.\u001B[39misfile(posixpath\u001B[38;5;241m.\u001B[39mjoin(dataset_path, config\u001B[38;5;241m.\u001B[39mDATASETDICT_JSON_FILENAME)):\n\u001B[1;32m   2695\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m DatasetDict\u001B[38;5;241m.\u001B[39mload_from_disk(dataset_path, keep_in_memory\u001B[38;5;241m=\u001B[39mkeep_in_memory, storage_options\u001B[38;5;241m=\u001B[39mstorage_options)\n",
      "File \u001B[0;32m~/PycharmProjects/autoregressive_playground/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:1753\u001B[0m, in \u001B[0;36mDataset.load_from_disk\u001B[0;34m(dataset_path, fs, keep_in_memory, storage_options)\u001B[0m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(dataset_info_path, encoding\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m dataset_info_file:\n\u001B[1;32m   1751\u001B[0m     dataset_info \u001B[38;5;241m=\u001B[39m DatasetInfo\u001B[38;5;241m.\u001B[39mfrom_dict(json\u001B[38;5;241m.\u001B[39mload(dataset_info_file))\n\u001B[0;32m-> 1753\u001B[0m dataset_size \u001B[38;5;241m=\u001B[39m \u001B[43mestimate_dataset_size\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1754\u001B[0m \u001B[43m    \u001B[49m\u001B[43mPath\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdest_dataset_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_file\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfilename\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata_file\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m_data_files\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m   1755\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1756\u001B[0m keep_in_memory \u001B[38;5;241m=\u001B[39m keep_in_memory \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m is_small_dataset(dataset_size)\n\u001B[1;32m   1757\u001B[0m table_cls \u001B[38;5;241m=\u001B[39m InMemoryTable \u001B[38;5;28;01mif\u001B[39;00m keep_in_memory \u001B[38;5;28;01melse\u001B[39;00m MemoryMappedTable\n",
      "File \u001B[0;32m~/PycharmProjects/autoregressive_playground/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py:724\u001B[0m, in \u001B[0;36mestimate_dataset_size\u001B[0;34m(paths)\u001B[0m\n\u001B[1;32m    723\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mestimate_dataset_size\u001B[39m(paths):\n\u001B[0;32m--> 724\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msum\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mst_size\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpath\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mpaths\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/autoregressive_playground/.venv/lib/python3.10/site-packages/datasets/utils/file_utils.py:724\u001B[0m, in \u001B[0;36m<genexpr>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    723\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mestimate_dataset_size\u001B[39m(paths):\n\u001B[0;32m--> 724\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msum\u001B[39m(\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mst_size \u001B[38;5;28;01mfor\u001B[39;00m path \u001B[38;5;129;01min\u001B[39;00m paths)\n",
      "File \u001B[0;32m~/.local/share/uv/python/cpython-3.10-linux-x86_64-gnu/lib/python3.10/pathlib.py:1097\u001B[0m, in \u001B[0;36mPath.stat\u001B[0;34m(self, follow_symlinks)\u001B[0m\n\u001B[1;32m   1092\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mstat\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m, follow_symlinks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m   1093\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1094\u001B[0m \u001B[38;5;124;03m    Return the result of the stat() system call on this path, like\u001B[39;00m\n\u001B[1;32m   1095\u001B[0m \u001B[38;5;124;03m    os.stat() does.\u001B[39;00m\n\u001B[1;32m   1096\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1097\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_accessor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_symlinks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_symlinks\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/peter/PycharmProjects/autoregressive_playground/instruction_following/tokenized_data/robots_test/data-00000-of-00001.arrow'"
     ]
    }
   ],
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
