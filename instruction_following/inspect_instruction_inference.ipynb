{
 "cells": [
  {
   "cell_type": "code",
   "id": "809914ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.547612632Z",
     "start_time": "2026-02-22T23:22:13.477725753Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from chat_template import chat_template\n",
    "from model import ChatModel\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50, temperature=0.3, top_k=10, argmax=False, stop_tokens=None):\n",
    "    idx = torch.tensor(\n",
    "        [tokenizer.encode(start, add_special_tokens=False).ids],\n",
    "        device=device,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        top_logits, top_pos = torch.topk(logits, top_k)\n",
    "        logits = torch.where(\n",
    "            logits < top_logits[:, -1],\n",
    "            input=torch.tensor(float(\"-inf\")),\n",
    "            other=logits\n",
    "        )\n",
    "\n",
    "        probs = nn.functional.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "        if argmax:\n",
    "            next_id = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "        if stop_tokens and next_id.item() in stop_tokens:\n",
    "            print(\"Reached stop token\")\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "outputs": [],
   "execution_count": 182
  },
  {
   "cell_type": "code",
   "id": "4552ef70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.587738919Z",
     "start_time": "2026-02-22T23:22:13.548108092Z"
    }
   },
   "source": [
    "minified = True\n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=ModelSettings.max_context_length,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=64,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=0.0,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 183
  },
  {
   "cell_type": "code",
   "id": "3d29b4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.621002975Z",
     "start_time": "2026-02-22T23:22:13.588382784Z"
    }
   },
   "source": [
    "step = 999\n",
    "state = torch.load(f\"instruction_checkpoints/state/{step:05d}.pt\", map_location=torch.device('cpu'))"
   ],
   "outputs": [],
   "execution_count": 184
  },
  {
   "cell_type": "code",
   "id": "d06a9442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.631489709Z",
     "start_time": "2026-02-22T23:22:13.623513251Z"
    }
   },
   "source": [
    "state_dict = state[\"model\"]\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k, v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)"
   ],
   "outputs": [],
   "execution_count": 185
  },
  {
   "cell_type": "code",
   "id": "3bb2db89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.659478634Z",
     "start_time": "2026-02-22T23:22:13.632941125Z"
    }
   },
   "source": [
    "model.load_state_dict(state[\"model\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 186
  },
  {
   "cell_type": "code",
   "id": "c2fb924f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.685207460Z",
     "start_time": "2026-02-22T23:22:13.661868856Z"
    }
   },
   "source": [
    "stop_tokens = tokenizer.encode(special_tokens[\"end_of_turn\"] + special_tokens[\"eos\"], add_special_tokens=False).ids\n",
    "print(stop_tokens)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "execution_count": 187
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:13.696711687Z",
     "start_time": "2026-02-22T23:22:13.686578272Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_completion(user_text):\n",
    "    return generate(\n",
    "        model,\n",
    "        chat_template([\n",
    "            {\"role\": \"user\", \"content\": user_text}\n",
    "        ]),\n",
    "        max_new_tokens=200,\n",
    "        stop_tokens=stop_tokens\n",
    "    )"
   ],
   "id": "176cf1aa7e65673c",
   "outputs": [],
   "execution_count": 188
  },
  {
   "cell_type": "code",
   "id": "92d5c415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-22T23:22:41.821720947Z",
     "start_time": "2026-02-22T23:22:41.637109053Z"
    }
   },
   "source": "chat_completion(\"Briefly describe gravity\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached stop token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Briefly describe gravity\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 194
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
