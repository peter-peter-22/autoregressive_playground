{
 "cells": [
  {
   "cell_type": "code",
   "id": "809914ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:12.792399716Z",
     "start_time": "2026-02-23T12:31:12.386537018Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import load_from_disk\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from chat_template import chat_template\n",
    "from model import ChatModel\n",
    "from settings import ModelSettings\n",
    "from special_tokens import special_tokens\n",
    "\n",
    "tokenizer = Tokenizer.from_file(\"tokenizer.json\")\n",
    "device = \"cpu\"\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model, start, max_new_tokens=50, temperature=0.3, top_k=10, argmax=False, stop_tokens=None):\n",
    "    idx = torch.tensor(\n",
    "        [[tokenizer.token_to_id(special_tokens[\"bos\"])]+ tokenizer.encode(start, add_special_tokens=False).ids],\n",
    "        device=device,\n",
    "        dtype=torch.long,\n",
    "    )\n",
    "    print(list(map(tokenizer.id_to_token,idx[0].tolist())))\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -ModelSettings.max_context_length:]\n",
    "        logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        top_logits, top_pos = torch.topk(logits, top_k)\n",
    "        logits = torch.where(\n",
    "            logits < top_logits[:, -1],\n",
    "            input=torch.tensor(float(\"-inf\")),\n",
    "            other=logits\n",
    "        )\n",
    "\n",
    "        probs = nn.functional.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "        if argmax:\n",
    "            next_id = torch.argmax(probs, dim=-1, keepdim=True)\n",
    "        else:\n",
    "            next_id = torch.multinomial(probs, num_samples=1)\n",
    "        idx = torch.cat([idx, next_id], dim=1)\n",
    "\n",
    "        if stop_tokens and next_id.item() in stop_tokens:\n",
    "            print(\"Reached stop token\")\n",
    "            break\n",
    "\n",
    "    return tokenizer.decode(idx[0].tolist())"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "id": "4552ef70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:14.749225047Z",
     "start_time": "2026-02-23T12:31:12.837440875Z"
    }
   },
   "source": [
    "minified = False\n",
    "\n",
    "if not minified:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=ModelSettings.embedding_size,\n",
    "        max_context_length=ModelSettings.max_context_length,\n",
    "        ff_size_multiplier=ModelSettings.ff_size_multiplier,\n",
    "        transformer_blocks=ModelSettings.transformer_blocks,\n",
    "        attention_heads=ModelSettings.attention_heads,\n",
    "        dropout=ModelSettings.dropout,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )\n",
    "else:\n",
    "    model = ChatModel(\n",
    "        vocabulary_size=ModelSettings.vocabulary_size,\n",
    "        embedding_size=64,\n",
    "        max_context_length=64,\n",
    "        ff_size_multiplier=2,\n",
    "        transformer_blocks=4,\n",
    "        attention_heads=4,\n",
    "        dropout=ModelSettings.dropout,\n",
    "        bias=ModelSettings.bias,\n",
    "        device=device,\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n",
      "using flash attention\n"
     ]
    }
   ],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "id": "3d29b4ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:16.826176901Z",
     "start_time": "2026-02-23T12:31:16.290999956Z"
    }
   },
   "source": [
    "step = 5999\n",
    "state = torch.load(f\"instruction_output_colab/{step:05d}_with_dropout.pt\", map_location=torch.device('cpu'))"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "id": "d06a9442",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:18.196800755Z",
     "start_time": "2026-02-23T12:31:18.107811026Z"
    }
   },
   "source": [
    "state_dict = state[\"model\"]\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k, v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "id": "3bb2db89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:18.558634452Z",
     "start_time": "2026-02-23T12:31:18.295835325Z"
    }
   },
   "source": [
    "model.load_state_dict(state[\"model\"])"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "id": "c2fb924f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:18.862462759Z",
     "start_time": "2026-02-23T12:31:18.577570211Z"
    }
   },
   "source": [
    "stop_tokens = tokenizer.encode(special_tokens[\"end_of_turn\"] + special_tokens[\"eos\"], add_special_tokens=False).ids\n",
    "print(stop_tokens)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n"
     ]
    }
   ],
   "execution_count": 96
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:18.920166698Z",
     "start_time": "2026-02-23T12:31:18.893828608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def chat_completion(user_text):\n",
    "    return generate(\n",
    "        model,\n",
    "        chat_template([\n",
    "            {\"role\": \"user\", \"content\": user_text}\n",
    "        ],add_generation_token=True),\n",
    "        max_new_tokens=200,\n",
    "        stop_tokens=stop_tokens,\n",
    "    )"
   ],
   "id": "176cf1aa7e65673c",
   "outputs": [],
   "execution_count": 97
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:31:19.069254488Z",
     "start_time": "2026-02-23T12:31:18.924676836Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_dir = \"tokenized_data\"\n",
    "test_ds_name = data_dir + \"/test_chats\"\n",
    "ds_train = load_from_disk(test_ds_name).take(10).shuffle(0)\n",
    "token_ids=next(iter(ds_train))[\"tokens\"]\n",
    "tokenizer.decode(token_ids)"
   ],
   "id": "958e123b985341a9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Write one paragraph about the Tlachihualtepetl pyramid. Keep it at or below 15 sentences. Include its size and when it was built. Also, include any aspects of worship it had. Include aspects of its more recent history, too. Name at least one specific year. \\nWhen people hear the word \"pyramid,\" they often think of Egypt. However, the world\\'s largest pyramid is in Cholula, Mexico. Tlachihualtepetl, also called the Great Pyramid of Cholula, is 217 feet (66 meters) tall and its base is 1,476 by 1,1476 feet (450 by 450 meters). Its total volume is 157 million cubic feet. Due to its size, it took centuries to build. It was worked on several different times between 300 BC and 700 AD. There was a temple above it to worship Quetzalcoatl - the Aztec god of learning and books. However, the temple was abandoned around the 8th or 9th century AD. Over time, it became covered with vegetation. As a result, it blended in and Spaniards first mistook it for a hill when they conquered Mexico in 1521. They replaced the temple with a church and the pyramid stayed hidden until the 1930s when the earth started to erode. Archeologists have excavated and studied many parts of the pyramid since then, including the altars. It has also become a tourist attraction since then. Thousands of people visit Tlachihualtepetl each year. \\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "code",
   "id": "92d5c415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:32:16.930046285Z",
     "start_time": "2026-02-23T12:31:19.133398005Z"
    }
   },
   "source": [
    "# test\n",
    "chat_completion(\"Write one paragraph about the Tlachihualtepetl pyramid.\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|bos|>', '<|user|>', 'W', 'rite', 'Ġone', 'Ġparagraph', 'Ġabout', 'Ġthe', 'ĠT', 'l', 'ach', 'ih', 'ual', 't', 'ep', 'et', 'l', 'Ġpyramid', '.', '<|endofturn|>', 'Ċ', '<|assistant|>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Write one paragraph about the Tlachihualtepetl pyramid.\\nTlachihualtepetlmin. The tlachihialtepetepetl. The t-shutlach seepetl-epet-epet-epet-epetl-epet-epet-epet-epet-epet-l-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet-epet'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:32:38.431961225Z",
     "start_time": "2026-02-23T12:32:18.124948229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "chat_completion(\"I'm trying to create a menu with different kinds of pasta. Help me come up with different types of pasta and what they are best used for.\")"
   ],
   "id": "5772c7198d4e2387",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|bos|>', '<|user|>', 'I', \"'m\", 'Ġtrying', 'Ġto', 'Ġcreate', 'Ġa', 'Ġmenu', 'Ġwith', 'Ġdifferent', 'Ġkinds', 'Ġof', 'Ġpasta', '.', 'ĠHelp', 'Ġme', 'Ġcome', 'Ġup', 'Ġwith', 'Ġdifferent', 'Ġtypes', 'Ġof', 'Ġpasta', 'Ġand', 'Ġwhat', 'Ġthey', 'Ġare', 'Ġbest', 'Ġused', 'Ġfor', '.', '<|endofturn|>', 'Ċ', '<|assistant|>']\n",
      "Reached stop token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm trying to create a menu with different kinds of pasta. Help me come up with different types of pasta and what they are best used for.\\nHere are a few pasta that are best used for a pasta:\\n1. Cauliflower. This pasta is great for pasta and can be used to make it a pasta-together recipe.\\n2. Parmesan. This pasta is great for pasta and pasta.\\n3. Parmesan. Parmesan is a pasta-together pasta.\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 100
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:33:30.325972407Z",
     "start_time": "2026-02-23T12:32:40.138753565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# train\n",
    "chat_completion(\"Write me an acrostic poem about cheese.\")"
   ],
   "id": "e18d57a8385c2142",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|bos|>', '<|user|>', 'W', 'rite', 'Ġme', 'Ġan', 'Ġac', 'ro', 'stic', 'Ġpoem', 'Ġabout', 'Ġcheese', '.', '<|endofturn|>', 'Ċ', '<|assistant|>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Write me an acrostic poem about cheese.\\nOh, I love,\\nOh, I love,\\nOh, how can I love you?\\nOh, I love you,\\nOh, I love you,\\nOh, how can I love you?\\nOh, I love you, you love you,\\nOh, how can I love you,\\nOh, how I love you,\\nI love you, love you,\\nOh, how love you,\\nOh, how love you, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you, my love,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love, I love you,\\nOh, how love you, how love you,\\nOh, how love you,\\nOh'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-23T12:34:58.752354214Z",
     "start_time": "2026-02-23T12:34:40.064029468Z"
    }
   },
   "cell_type": "code",
   "source": "chat_completion(\"When did Michael Jackson pass away?\")",
   "id": "a7dcb26d3a167594",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|bos|>', '<|user|>', 'When', 'Ġdid', 'ĠMichael', 'ĠJackson', 'Ġpass', 'Ġaway', '?', '<|endofturn|>', 'Ċ', '<|assistant|>']\n",
      "Reached stop token\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"When did Michael Jackson pass away?\\n Michael Jackson's first walked away from the United States on August 14, 1969. He was the second in the first place to walk away from the American States. He was the second to walk away from the country in the country and was the second to walk away from the country. He was also the second to walk away from the country in the country in the country.\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "I completed the available tutorials and built a minified GPT-2 clone.\n",
    "I have issues with the result of the instruction training.\n",
    "The resulting model can somewhat answer chat messages, but it's very inconfident.\n",
    "It often answers something unrelated, or repeats the same words.\n",
    "It can give a coherent answer only around 1 of 3 messages.\n",
    "With dropout, the validation loss converges at ~4.25 and the training loss at ~3.2\n",
    "Without dropout, the validation loss converges at ~5 and the training loss at ~0\n",
    "What causes this? Too small model? Bad training?\n",
    "\n",
    "The model:\n",
    "- context length: 1000\n",
    "- embedding dimensions: 384\n",
    "- attention heads: 12\n",
    "- transformer blocks: 12\n",
    "- FFN width multilier: 4\n",
    "- vocabulary size: 24k\n",
    "- params: ~40M\n",
    "\n",
    "Techniques:\n",
    "- weight tying\n",
    "- custom initialized weights\n",
    "- custom optimizer config with gradient decay groups\n",
    "- gradient clipping\n",
    "- cuda optimizations\n",
    "- temperature: 0.1, top_k: 10\n",
    "- the chat inference stops when reaching EOS or end_of_turn tokens\n",
    "- The chat inference adds the generation token\n",
    "\n",
    "Pre-training:\n",
    "- dropout: 0\n",
    "- training tokens: 3B (too large)\n",
    "- unique tokens: 1.5B\n",
    "- learning rate schedule: peak 6e-4, min 6e-5\n",
    "- batch size: 32\n",
    "- BOS, EOS, end_of_text tokens\n",
    "- The generated text here is pretty confident, but the repeating still appears sometimes\n",
    "\n",
    "Instruction training:\n",
    "- dropout: 0.1\n",
    "- training chats: 5 * 9500\n",
    "- unique chats: 9500\n",
    "- learning rate: fixed, 1e-5\n",
    "- batch size: 8 (smaller, because it was trained on a different GPU)\n",
    "- I checked the training data, loss masking, attention masking, special tokens\n",
    "\n",
    "\n",
    "Examples chats:\n",
    "\n",
    "- User: When did Michael Jackson pass away?\n",
    "- Assistant: Michael Jackson's first walked away from the United States on August 14, 1969. He was the second in the first place to walk away from the American States. He was the second to walk away from the country in the country and was the second to walk away from the country. He was also the second to walk away from the country in the country in the country.\n",
    "\n",
    "- User: Write me an acrostic poem about cheese.\n",
    "- Assistant: Oh, I love,\\nOh, I love,\\nOh, how can I love you?\\nOh, I love you,\\nOh, I love you,\\nOh, how can I love you?\\nOh, I love you, you love you,\\nOh, how can I love you,\\nOh, how I love you,\\nI love you, love you,\\nOh, how love you,\\nOh, how love you, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you, my love,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love you,\\nOh, how love, I love you,\\nOh, how love you, how love you,\\nOh, how love you,\\nOh\n",
    "\n",
    "- User: I'm trying to create a menu with different kinds of pasta. Help me come up with different types of pasta and what they are best used for.\n",
    "- Assistant: Here are a few pasta that are best used for a pasta:\\n1. Cauliflower. This pasta is great for pasta and can be used to make it a pasta-together recipe.\\n2. Parmesan. This pasta is great for pasta and pasta.\\n3. Parmesan. Parmesan is a pasta-together pasta."
   ],
   "id": "5b1820a314f4c2f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b812dd9b9d73001c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pythonproject1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
